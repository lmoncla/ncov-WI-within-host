{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Examine the effects of geography and divergence on proportion of variants shared among samples \n",
    "\n",
    "June 24, 2020 \n",
    "\n",
    "We would like to determine whether samples collected in the same geographic area share more variants than expected by chance alone. In addition to the permutation test, I would also like to perform some sort of metric for whether being close together on the tree also predicts having shared variation. There are probably a few different ways to do this: \n",
    "\n",
    "1. Compare some sort of raw measure of sequence divergence, like hamming distance (number of differences/length of sequence)\n",
    "2. Compare the branch length of the path between the 2 sequences. \n",
    "3. Compare the tmrca, where more divergent sequences will have older tmrcas.\n",
    "\n",
    "All 3 of these could be proxies for how close together sequences are on the tree. It would be good to test this out using the Wisconsin-only build as well as the Wisconsin-focused build with other sequences in there for context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The rpy2.ipython extension is already loaded. To reload it, use:\n",
      "  %reload_ext rpy2.ipython\n"
     ]
    }
   ],
   "source": [
    "import imp\n",
    "import importlib, json\n",
    "import glob\n",
    "import re,copy,json\n",
    "import Bio.Phylo\n",
    "import requests\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "\n",
    "import copy\n",
    "from scipy.special import binom\n",
    "import datetime as dt\n",
    "    \n",
    "import rpy2\n",
    "%load_ext rpy2.ipython\n",
    "\n",
    "# for this to work, you will need to download the most recent version of baltic, available here \n",
    "bt = imp.load_source('baltic', '/Users/lmoncla/src/baltic/baltic/baltic.py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_shared_variant_proportion(sample1,sample2,df):\n",
    "    shared_variants = 0\n",
    "    \n",
    "    s1_df = df[df['strain_name'] == sample1]\n",
    "    variants_in_s1 = set(s1_df['minor_nuc_muts'].tolist())\n",
    "    \n",
    "    s2_df = df[df['strain_name'] == sample2]\n",
    "    variants_in_s2 = set(s2_df['minor_nuc_muts'].tolist())\n",
    "    \n",
    "    total_variants = len(variants_in_s1) + len(variants_in_s2)\n",
    "    \n",
    "    for v in variants_in_s1:\n",
    "        if v in variants_in_s2:\n",
    "            shared_variants += 2\n",
    "            \n",
    "    proportion_shared = float(shared_variants/total_variants)\n",
    "            \n",
    "    return(proportion_shared)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in VCF data and output SNVs to query into a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"to load in an ipython notebook as a module, just run the following. You will now have access to all of the \n",
    "functions written in that jupyter notebook\"\"\"\n",
    "\n",
    "%run vcf-module.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lmoncla/anaconda/envs/LHM-basics/lib/python3.7/site-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  after removing the cwd from sys.path.\n",
      "/Users/lmoncla/anaconda/envs/LHM-basics/lib/python3.7/site-packages/ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"\n",
      "/Users/lmoncla/anaconda/envs/LHM-basics/lib/python3.7/site-packages/ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "/Users/lmoncla/anaconda/envs/LHM-basics/lib/python3.7/site-packages/ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if __name__ == '__main__':\n",
      "/Users/lmoncla/anaconda/envs/LHM-basics/lib/python3.7/site-packages/ipykernel_launcher.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  # Remove the CWD from sys.path while we load stuff.\n",
      "/Users/lmoncla/anaconda/envs/LHM-basics/lib/python3.7/site-packages/ipykernel_launcher.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if sys.path[0] == '':\n",
      "/Users/lmoncla/anaconda/envs/LHM-basics/lib/python3.7/site-packages/ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "/Users/lmoncla/anaconda/envs/LHM-basics/lib/python3.7/site-packages/ipykernel_launcher.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "/Users/lmoncla/anaconda/envs/LHM-basics/lib/python3.7/site-packages/ipykernel_launcher.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "\"\"\"now, input the strain names file/metadata file, the directory containing the vcfs, and return the dataframess\"\"\"\n",
    "\n",
    "strain_names_file = \"/Users/lmoncla/src/ncov-WI-within-host/data/sample-metadata.tsv\"\n",
    "fasta_file = \"/Users/lmoncla/src/ncov-WI-within-host/data/sample-avrl.fasta\"\n",
    "clades_file = \"/Users/lmoncla/src/ncov-WI-within-host/data/clades-file-2020-08-28.txt\"\n",
    "vcf_directory = \"/Users/lmoncla/src/ncov-WI-within-host/data/vcfs-all/\"\n",
    "samples_to_ignore = [\"N_transcript\"]\n",
    "\n",
    "snvs_only, indels_only, all_intersection_variants,metadata_dict = return_dataframes(strain_names_file, clades_file,vcf_directory,samples_to_ignore,fasta_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "376\n",
      "124\n",
      "500\n"
     ]
    }
   ],
   "source": [
    "snvs_to_query = set(snvs_only['minor_nuc_muts'])\n",
    "indels_to_query = set(indels_only['minor_nuc_muts'])\n",
    "all_variants_to_query = snvs_to_query.copy()\n",
    "all_variants_to_query.update(indels_to_query)\n",
    "print(len(snvs_to_query))\n",
    "print(len(indels_to_query))\n",
    "print(len(all_variants_to_query))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code for parsing through tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"This is a small, recursive function to return the TMRCA for 2 tips. Starting with the parental node of tip1,\n",
    "go recursively backwards in the tree until you find an internal node whose children contains both tip1 and \n",
    "tip2. Return that node.\"\"\"\n",
    "\n",
    "def return_TMRCA_node(input_node,tip1,tip2):\n",
    "    \n",
    "    # for a given internal node, generate a list of all its children, i.e., tips descending from that node\n",
    "    node = input_node\n",
    "    children = list(node.children)   # .children will output all of the direct descendants as baltic objects\n",
    "    leaves = list(node.leaves)       # .leaves will output the names of all tips descending from the node\n",
    "    \n",
    "    if tip2 in leaves and tip1 in leaves: \n",
    "        node_to_return = node\n",
    "    else:\n",
    "        node_to_return = return_TMRCA_node(node.parent,tip1,tip2)\n",
    "            \n",
    "    return(node_to_return)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"given 2 tips and a tree, iterate through the tree. when we reach tip 1, run return_TMRCA_node, to find the \n",
    "internal node that is the TMRCA for tips 1 and 2. Extract its date and return the node object and date\"\"\"\n",
    "\n",
    "def return_TMRCA(tip1,tip2,tree):\n",
    "    for k in tree.Objects: \n",
    "        if k.branchType == \"leaf\" and k.name == tip1:\n",
    "            tmrca_node = return_TMRCA_node(k.parent,tip1,tip2)\n",
    "            date = tmrca_node.traits['node_attrs']['num_date']['value']  # output the mean inferred date\n",
    "            \n",
    "    return(tmrca_node, date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Given a starting internal node, and a tip you would like to end at, traverse the full path from that node to\n",
    "tip. Along the way, gather nucleotide mutations that occur along that path. Once you have reached the ending \n",
    "tip, return the list of mutations that fell along that path\"\"\"\n",
    "\n",
    "def return_divergence_on_path_to_tip(starting_node, ending_tip):\n",
    "    \n",
    "    children = starting_node.children\n",
    "    \n",
    "    for child in children:\n",
    "        \n",
    "        \"\"\"if the child is a leaf: if leaf is the target end tip, collect its divergence and return; \n",
    "        if leaf is not the target end tip, move on\"\"\"\n",
    "        \"\"\"if the child is an internal node: first, test whether that child node contains the target tips in its \n",
    "        children. child.leaves will output a list of the names of all tips descending from that node. If not, pass. \n",
    "        if the node does contain the target end tip in its leaves, keep traversing down that node recursively\"\"\"\n",
    "\n",
    "        if child.branchType == \"leaf\":\n",
    "            if child.name != ending_tip:\n",
    "                pass\n",
    "            elif child.name == ending_tip:\n",
    "                child_divergence = child.traits['node_attrs']['div']\n",
    "                return(child_divergence)\n",
    "         \n",
    "        elif child.branchType == \"node\":\n",
    "            if ending_tip not in child.leaves:\n",
    "                pass\n",
    "            else:\n",
    "                child_divergence = return_divergence_on_path_to_tip(child, ending_tip)\n",
    "    \n",
    "    return(child_divergence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_clade(tipname, tree):\n",
    "    for k in tree.Objects:\n",
    "        if k.branchType == \"leaf\" and k.name == tipname:\n",
    "            clade = k.traits['node_attrs']['clade_membership']['value']\n",
    "    return(clade)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_all_Wisconsin_tips(tree):\n",
    "    Wisconsin_leaves = []\n",
    "    \n",
    "    for k in tree.Objects: \n",
    "        if k.branchType == \"leaf\":\n",
    "            division = k.traits['node_attrs']['division']['value']\n",
    "            if division == \"Wisconsin\":\n",
    "                Wisconsin_leaves.append(k.name)\n",
    "                \n",
    "    return(Wisconsin_leaves)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_mean_Ct(metadata,tip):\n",
    "    Cts = []\n",
    "    \n",
    "    Ct1 = metadata[tip]['Ct1']\n",
    "    Ct2 = metadata[tip]['Ct2']\n",
    "    \n",
    "    if Ct1 not in [\"\",\"-\"]:\n",
    "        Cts.append(Ct1)\n",
    "    if Ct2 not in [\"\",\"-\"]:\n",
    "        Cts.append(Ct2)\n",
    "    \n",
    "    # now find mean \n",
    "    Ct_sum = 0\n",
    "    for c in Cts: \n",
    "        Ct_sum += float(c)\n",
    "        \n",
    "    if len(Cts) > 0:\n",
    "        mean = float(Ct_sum)/len(Cts)\n",
    "    else: \n",
    "        mean = 'NaN'\n",
    "    \n",
    "    return(mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_Cts(tip1,tip2,metadata):\n",
    "    tip1_Ct = return_mean_Ct(metadata,tip1)\n",
    "    tip2_Ct = return_mean_Ct(metadata,tip2)\n",
    "    \n",
    "    if tip1_Ct != 'NaN' and tip2_Ct != 'NaN':\n",
    "        difference = abs(tip1_Ct-tip2_Ct)\n",
    "    else:\n",
    "        difference = 'NaN'\n",
    "    return(difference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_location(tip1,tip2,metadata):\n",
    "    geo1 = metadata[tip1][\"location\"]\n",
    "    geo2 = metadata[tip2][\"location\"]\n",
    "    \n",
    "    if geo1 == geo2: \n",
    "        location = 1\n",
    "    else: \n",
    "        location = 0\n",
    "        \n",
    "    return(location,geo1,geo2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_lat_longs_dictionary(lat_longs_file):\n",
    "    \n",
    "    output_dict = {}\n",
    "    \n",
    "    with open(lat_longs_file, \"r\") as infile: \n",
    "        for line in infile:\n",
    "            if len(line.split(\"\\t\")) == 4:\n",
    "                location = line.split(\"\\t\")[1]\n",
    "                longitude = line.split(\"\\t\")[2]\n",
    "                latitude = line.split(\"\\t\")[3].strip()\n",
    "                output_dict[location] = {\"latitude\":latitude, \"longitude\":longitude}\n",
    "    return(output_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"I took this from here, https://stackoverflow.com/questions/4913349/haversine-formula-in-python-bearing-and-distance-between-two-gps-points\n",
    "A decent overview of this formula can be found here: https://www.movable-type.co.uk/scripts/latlong.html\"\"\"\n",
    "from math import radians, cos, sin, asin, sqrt\n",
    "\n",
    "def haversine(lon1, lat1, lon2, lat2):\n",
    "    \"\"\"\n",
    "    Calculate the great circle distance between two points \n",
    "    on the earth (specified in decimal degrees). \n",
    "    \"\"\"\n",
    "    # convert decimal degrees to radians \n",
    "    lon1, lat1, lon2, lat2 = map(radians, [lon1, lat1, lon2, lat2])\n",
    "\n",
    "    # haversine formula \n",
    "    dlon = lon2 - lon1 \n",
    "    dlat = lat2 - lat1 \n",
    "    a = sin(dlat/2)**2 + cos(lat1) * cos(lat2) * sin(dlon/2)**2\n",
    "    c = 2 * asin(sqrt(a)) \n",
    "    r = 6371 # Radius of earth in kilometers. Use 3956 for miles\n",
    "    return c * r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_distance_between_locations(tip1,tip2,metadata,lat_longs):\n",
    "    geo1 = metadata[tip1][\"location\"]\n",
    "    geo2 = metadata[tip2][\"location\"]\n",
    "    \n",
    "    if geo1 != \"\" and geo2 != \"\":\n",
    "        lat1 = lat_longs_dict[geo1]['latitude']\n",
    "        lat2 = lat_longs_dict[geo2]['latitude']\n",
    "\n",
    "        long1 = lat_longs_dict[geo1]['longitude']\n",
    "        long2 = lat_longs_dict[geo2]['longitude']\n",
    "\n",
    "        distance_km = haversine(float(long1), float(lat1), float(long2), float(lat2))\n",
    "    else:\n",
    "        distance_km = 'NaN'\n",
    "    return(distance_km)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# run!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tree height: 0.632565\n",
      "Tree length: 418.027815\n",
      "multitype tree\n",
      "annotations present\n",
      "\n",
      "Numbers of objects in tree: 15126 (7176 nodes and 7950 leaves)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# test this out first on the Wisconsin-only build json\n",
    "WI_tree_path = \"/Users/lmoncla/src/ncov-WI-within-host/data/ncov_wisconsin_global-context.json\"\n",
    "#WI_tree_path = \"/Volumes/gradschool-and-postdoc-backups/post-doc/stored_files_too_big_for_laptop/ncov-build-forced-WI/ncov/auspice/ncov_usa_wisconsin.json\"\n",
    "\n",
    "analysis_level = \"division\"\n",
    "\n",
    "with open(WI_tree_path) as json_file:\n",
    "    WI_tree_json = json.load(json_file)\n",
    "WI_tree_object=WI_tree_json['tree']\n",
    "WI_meta=WI_tree_json['meta']\n",
    "json_translation={'absoluteTime':lambda k: k.traits['node_attrs']['num_date']['value'],'name':'name'} ## allows baltic to find correct attributes in JSON, height and name are required at a minimum\n",
    "json_meta={'file':WI_meta,'traitName':analysis_level} ## if you want auspice stylings you can import the meta file used on nextstrain.org\n",
    "\n",
    "WI_tree=bt.loadJSON(WI_tree_object,json_translation,json_meta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The putative transmission pairs are: \n",
    "1. USA/WI-UW-65/2020 and USA/WI-UW-32/2020  (2 days apart)\n",
    "2. USA/WI-UW-41/2020 and USA/WI-UW-48/2020 (same day)\n",
    "3. USA/WI-UW-74/2020 and USA/WI-UW-29/2020 (4 days apart)\n",
    "4. USA/WI-UW-120/2020 and USA/WI-UW-119/2020 (3 days apart)\n",
    "5. USA/WI-UW-333/2020 and USA/WI-UW-334/2020 (same day)\n",
    "6. USA/WI-UW-337/2020 and USA/WI-UW-338/2020 (same day) -> I am actually excluding these, because they do not have the same consensus sequence; they are 3 mutations different, which seems pretty unlikely\n",
    "7. USA/WI-UW-158/2020 and USA/WI-UW-159/2020 and USA/WI-UW-160/2020  (these are all in the same household, all collected on the same day) -> I am also going to call 158 and 160 true transmission pairs because they have the same consensus sequence, while 159 has 2 additional mutations (158 and 160 isolated same day). 159 does look like it be descendant from 158 and 160, but becuase it has 2 mutations different tthey were all collected on the same day, it seems a little weird.\n",
    "\n",
    "pairs 5 and 6 are from the Milwaukee area, whereas the rest are more from the Madison area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "transmission_pairs = [[\"USA/WI-UW-65/2020\",\"USA/WI-UW-32/2020\"],[\"USA/WI-UW-41/2020\",\"USA/WI-UW-48/2020\"],\n",
    "                      [\"USA/WI-UW-74/2020\",\"USA/WI-UW-29/2020\"],[\"USA/WI-UW-120/2020\",\"USA/WI-UW-119/2020\"],\n",
    "                     [\"USA/WI-UW-333/2020\",\"USA/WI-UW-334/2020\"],[\"USA/WI-UW-158/2020\",\"USA/WI-UW-160/2020\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1096\n"
     ]
    }
   ],
   "source": [
    "Wisconsin_tips_in_tree = return_all_Wisconsin_tips(WI_tree)\n",
    "print(len(Wisconsin_tips_in_tree))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "USA/DO NOT UPLOAD - time series sample/2020\n",
      "USA/DO NOT UPLOAD/2020\n",
      "103\n"
     ]
    }
   ],
   "source": [
    "tips_to_query = set(all_intersection_variants['strain_name'].tolist())\n",
    "\n",
    "not_in_tree = []\n",
    "for t in tips_to_query:\n",
    "    if t not in Wisconsin_tips_in_tree:\n",
    "        print(t)\n",
    "        not_in_tree.append(t)\n",
    "        \n",
    "print(len(tips_to_query))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "101\n"
     ]
    }
   ],
   "source": [
    "for n in not_in_tree:\n",
    "    tips_to_query.remove(n)\n",
    "print(len(tips_to_query))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in metadata and latitude and longitude files\n",
    "metadata_input_file = \"/Users/lmoncla/src/ncov-WI-within-host/data/sample-metadata.tsv\"\n",
    "metadata_dict = return_metadata_dict(metadata_input_file, clades_file)\n",
    "lat_longs_dict = return_lat_longs_dictionary(\"/Users/lmoncla/src/ncov/defaults/lat_longs.tsv\")\n",
    "wh_df_to_use = snvs_only\n",
    "tree = WI_tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame()\n",
    "\n",
    "combos = []\n",
    "for t in tips_to_query: \n",
    "    tip1 = t\n",
    "    \n",
    "    for a in tips_to_query:\n",
    "        tip2 = a\n",
    "        combo = set([tip1,tip2])\n",
    "        \n",
    "        if tip1 != tip2 and combo not in combos:   # to prevent doing the pairwise comparisons twice\n",
    "            \n",
    "            # output Cts\n",
    "            Ct_diff = compare_Cts(tip1,tip2,metadata_dict)\n",
    "            \n",
    "            # are the locations the same? 0 means no, 1 means yes\n",
    "            location,loc1,loc2 = compare_location(tip1,tip2,metadata_dict)\n",
    "            \n",
    "            # output great circle distance between locations\n",
    "            great_circle_distance = return_distance_between_locations(tip1,tip2,metadata_dict,lat_longs_dict)\n",
    "\n",
    "            # output their clades\n",
    "            tip1_clade = return_clade(tip1, tree)\n",
    "            tip2_clade = return_clade(tip2, tree)\n",
    "            if tip1_clade == tip2_clade:\n",
    "                clades_same = 1\n",
    "            else:\n",
    "                clades_same = 0\n",
    "\n",
    "            # output the tmrca and divergence\n",
    "            parental_node,tmrca_date = return_TMRCA(tip1,tip2,tree)\n",
    "            parent_divergence = parental_node.traits['node_attrs']['div']\n",
    "\n",
    "            tip1_divergence = return_divergence_on_path_to_tip(parental_node, tip1)\n",
    "            tip2_divergence = return_divergence_on_path_to_tip(parental_node, tip2)\n",
    "\n",
    "            node_to_tip1 = tip1_divergence - parent_divergence\n",
    "            node_to_tip2 = tip2_divergence - parent_divergence\n",
    "            total_divergence = node_to_tip1 + node_to_tip2\n",
    "\n",
    "            # calculate the proportion of variants shared\n",
    "            shared_proportion_snvs = compute_shared_variant_proportion(tip1,tip2,wh_df_to_use)\n",
    "\n",
    "            d = pd.DataFrame.from_dict({\"tip1\":[tip1],\"tip2\":[tip2],\"tmrca\":[tmrca_date],\"clades_same\":[clades_same],\n",
    "                                        \"divergence\":[total_divergence],\"prop_snvs_shared\":[shared_proportion_snvs],\n",
    "                                       \"Ct_diff\":[Ct_diff], \"location1\":[loc1],\"location2\":[loc2],\n",
    "                                       \"great_circle_distance_km\":[great_circle_distance],\"location_same\":[location],})\n",
    "\n",
    "            df = df.append(d)\n",
    "            combos.append(combo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5050"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write to csv so I can use it in R \n",
    "df.to_csv(\"../data/WI-variants-vs-geo-2020-09-09.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First, evaluate divergence \n",
    "\n",
    "I will first model shared diversity as a function of divergence. I will then model it as a combination of divergence, Ct differences and having the same clade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lmoncla/anaconda/envs/LHM-basics/lib/python3.7/site-packages/rpy2/robjects/pandas2ri.py:191: FutureWarning: from_items is deprecated. Please use DataFrame.from_dict(dict(items), ...) instead. DataFrame.from_dict(OrderedDict(items)) may be used to preserve the key order.\n",
      "  res = PandasDataFrame.from_items(items)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\n",
       "Call:\n",
       "glm(formula = prop_snvs_shared ~ divergence, family = gaussian(link = \"identity\"), \n",
       "    data = df, weights = na.action(na.omit))\n",
       "\n",
       "Deviance Residuals: \n",
       "     Min        1Q    Median        3Q       Max  \n",
       "-0.42374  -0.09296  -0.00088   0.08480   0.71872  \n",
       "\n",
       "Coefficients:\n",
       "             Estimate Std. Error t value Pr(>|t|)    \n",
       "(Intercept)  0.423743   0.004360   97.19   <2e-16 ***\n",
       "divergence  -0.020665   0.000372  -55.55   <2e-16 ***\n",
       "---\n",
       "Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1\n",
       "\n",
       "(Dispersion parameter for gaussian family taken to be 0.01898181)\n",
       "\n",
       "    Null deviance: 143.286  on 4464  degrees of freedom\n",
       "Residual deviance:  84.716  on 4463  degrees of freedom\n",
       "AIC: -5025.4\n",
       "\n",
       "Number of Fisher Scoring iterations: 2\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# evaluate the proportion of variants shared as a function of divergence\n",
    "%R -i df\n",
    "%R model.div = glm(prop_snvs_shared~divergence,data=df,family = gaussian(link=\"identity\"),na.action(na.omit))\n",
    "%R print(summary(model.div))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in eval(predvars, data, env) : \n",
      "  object 'great_circle_distance_km' not found\n",
      "\n",
      "Error in summary(model.geo) : object 'model.geo' not found\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lmoncla/anaconda/envs/LHM-basics/lib/python3.7/site-packages/rpy2/rinterface/__init__.py:146: RRuntimeWarning: Error in eval(predvars, data, env) : \n",
      "  object 'great_circle_distance_km' not found\n",
      "\n",
      "  warnings.warn(x, RRuntimeWarning)\n",
      "/Users/lmoncla/anaconda/envs/LHM-basics/lib/python3.7/site-packages/rpy2/rinterface/__init__.py:146: RRuntimeWarning: Error in summary(model.geo) : object 'model.geo' not found\n",
      "\n",
      "  warnings.warn(x, RRuntimeWarning)\n"
     ]
    }
   ],
   "source": [
    "# evaluate the proportion of variants shared as a function of great circle distance\n",
    "%R -i df\n",
    "%R model.geo = glm(prop_snvs_shared~great_circle_distance_km,data=df,family = gaussian(link=\"identity\"),na.action(na.omit))\n",
    "%R print(summary(model.geo))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in `contrasts<-`(`*tmp*`, value = contr.funs[1 + isOF[nn]]) : \n",
      "  contrasts can be applied only to factors with 2 or more levels\n",
      "\n",
      "Error in summary(model.div2) : object 'model.div2' not found\n",
      "\n",
      "Error in anova(model.div2, test = \"Chisq\") : \n",
      "  object 'model.div2' not found\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lmoncla/anaconda/envs/LHM-basics/lib/python3.7/site-packages/rpy2/rinterface/__init__.py:146: RRuntimeWarning: Error in `contrasts<-`(`*tmp*`, value = contr.funs[1 + isOF[nn]]) : \n",
      "  contrasts can be applied only to factors with 2 or more levels\n",
      "\n",
      "  warnings.warn(x, RRuntimeWarning)\n"
     ]
    }
   ],
   "source": [
    "# evaluate the proportion of variants shared as a function of Ct difference\n",
    "%R -i df\n",
    "%R model.div2 = glm(prop_snvs_shared~Ct_diff,data=df,family = gaussian(link=\"identity\"),na.action(na.omit))\n",
    "%R print(summary(model.div2))\n",
    "%R print(anova(model.div2, test=\"Chisq\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "Call:\n",
       "glm(formula = prop_snvs_shared ~ clades_same, family = gaussian(link = \"identity\"), \n",
       "    data = df, weights = na.action(na.omit))\n",
       "\n",
       "Deviance Residuals: \n",
       "     Min        1Q    Median        3Q       Max  \n",
       "-0.20805  -0.17344  -0.01959   0.12656   0.62656  \n",
       "\n",
       "Coefficients:\n",
       "             Estimate Std. Error t value Pr(>|t|)    \n",
       "(Intercept)  0.208053   0.005015  41.489  < 2e-16 ***\n",
       "clades_same -0.034615   0.005846  -5.921 3.44e-09 ***\n",
       "---\n",
       "Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1\n",
       "\n",
       "(Dispersion parameter for gaussian family taken to be 0.02967363)\n",
       "\n",
       "    Null deviance: 133.47  on 4464  degrees of freedom\n",
       "Residual deviance: 132.43  on 4463  degrees of freedom\n",
       "AIC: -3030.5\n",
       "\n",
       "Number of Fisher Scoring iterations: 2\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Analysis of Deviance Table\n",
       "\n",
       "Model: gaussian, link: identity\n",
       "\n",
       "Response: prop_snvs_shared\n",
       "\n",
       "Terms added sequentially (first to last)\n",
       "\n",
       "\n",
       "            Df Deviance Resid. Df Resid. Dev  Pr(>Chi)    \n",
       "NULL                         4464     133.47              \n",
       "clades_same  1   1.0402      4463     132.43 3.203e-09 ***\n",
       "---\n",
       "Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# lastly, try with clade same\n",
    "%R -i df\n",
    "%R model.div2 = glm(prop_snvs_shared~clades_same,data=df,family = gaussian(link=\"identity\"),na.action(na.omit))\n",
    "%R print(summary(model.div2))\n",
    "%R print(anova(model.div2, test=\"Chisq\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## now try all together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Error in eval(predvars, data, env) : \n",
      "  object 'great_circle_distance_km' not found\n",
      "\n",
      "Error in summary(model.marsh) : object 'model.marsh' not found\n",
      "\n",
      "Error in coef(model.marsh) : object 'model.marsh' not found\n",
      "\n",
      "Error in anova(model.marsh, test = \"Chisq\") : \n",
      "  object 'model.marsh' not found\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lmoncla/anaconda/envs/LHM-basics/lib/python3.7/site-packages/rpy2/rinterface/__init__.py:146: RRuntimeWarning: Error in summary(model.marsh) : object 'model.marsh' not found\n",
      "\n",
      "  warnings.warn(x, RRuntimeWarning)\n",
      "/Users/lmoncla/anaconda/envs/LHM-basics/lib/python3.7/site-packages/rpy2/rinterface/__init__.py:146: RRuntimeWarning: Error in coef(model.marsh) : object 'model.marsh' not found\n",
      "\n",
      "  warnings.warn(x, RRuntimeWarning)\n",
      "/Users/lmoncla/anaconda/envs/LHM-basics/lib/python3.7/site-packages/rpy2/rinterface/__init__.py:146: RRuntimeWarning: Error in anova(model.marsh, test = \"Chisq\") : \n",
      "  object 'model.marsh' not found\n",
      "\n",
      "  warnings.warn(x, RRuntimeWarning)\n"
     ]
    }
   ],
   "source": [
    "# evaluate the proportion of variants shared as a linear combination of divergence and whether the clade is the same\n",
    "%R -i df\n",
    "%R model.marsh = glm(prop_snvs_shared~divergence+clades_same+Ct_diff+great_circle_distance_km,data=df,family = gaussian(link=\"identity\"),na.action(na.omit))\n",
    "%R print(summary(model.marsh))\n",
    "%R print(coef(model.marsh))\n",
    "%R print(anova(model.marsh, test=\"Chisq\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 508,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "Call:\n",
       "glm(formula = prop_snvs_shared ~ divergence + clades_same + Ct_diff, \n",
       "    family = gaussian(link = \"identity\"), data = df, weights = na.action(na.omit))\n",
       "\n",
       "Deviance Residuals: \n",
       "     Min        1Q    Median        3Q       Max  \n",
       "-0.19530  -0.08062  -0.02077   0.08819   0.28793  \n",
       "\n",
       "Coefficients:\n",
       "             Estimate Std. Error t value Pr(>|t|)    \n",
       "(Intercept)  0.569131   0.023748  23.965   <2e-16 ***\n",
       "divergence  -0.003896   0.002032  -1.917   0.0571 .  \n",
       "clades_same  0.006918   0.022554   0.307   0.7595    \n",
       "Ct_diff      0.003609   0.003121   1.156   0.2494    \n",
       "---\n",
       "Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1\n",
       "\n",
       "(Dispersion parameter for gaussian family taken to be 0.01235454)\n",
       "\n",
       "    Null deviance: 1.9210  on 152  degrees of freedom\n",
       "Residual deviance: 1.8408  on 149  degrees of freedom\n",
       "AIC: -232.1\n",
       "\n",
       "Number of Fisher Scoring iterations: 2\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       " (Intercept)   divergence  clades_same      Ct_diff \n",
       " 0.569130801 -0.003895600  0.006918280  0.003608546 \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Analysis of Deviance Table\n",
       "\n",
       "Model: gaussian, link: identity\n",
       "\n",
       "Response: prop_snvs_shared\n",
       "\n",
       "Terms added sequentially (first to last)\n",
       "\n",
       "\n",
       "            Df Deviance Resid. Df Resid. Dev Pr(>Chi)  \n",
       "NULL                          152     1.9210           \n",
       "divergence   1 0.062623       151     1.8584  0.02436 *\n",
       "clades_same  1 0.001026       150     1.8573  0.77322  \n",
       "Ct_diff      1 0.016516       149     1.8408  0.24759  \n",
       "---\n",
       "Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# evaluate the proportion of variants shared as a linear combination of divergence and whether the clade is the same\n",
    "%R -i df\n",
    "%R model.marsh = glm(prop_snvs_shared~divergence+clades_same+Ct_diff,data=df,family = gaussian(link=\"identity\"),na.action(na.omit))\n",
    "%R print(summary(model.marsh))\n",
    "%R print(coef(model.marsh))\n",
    "%R print(anova(model.marsh, test=\"Chisq\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 509,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "Call:\n",
       "glm(formula = prop_snvs_shared ~ great_circle_distance_km + clades_same + \n",
       "    Ct_diff, family = gaussian(link = \"identity\"), data = df, \n",
       "    weights = na.action(na.omit))\n",
       "\n",
       "Deviance Residuals: \n",
       "     Min        1Q    Median        3Q       Max  \n",
       "-0.19447  -0.08212  -0.01615   0.07871   0.27799  \n",
       "\n",
       "Coefficients:\n",
       "                           Estimate Std. Error t value Pr(>|t|)    \n",
       "(Intercept)               0.5659632  0.0231075  24.493   <2e-16 ***\n",
       "great_circle_distance_km -0.0010747  0.0005681  -1.892   0.0605 .  \n",
       "clades_same              -0.0044782  0.0200395  -0.223   0.8235    \n",
       "Ct_diff                   0.0036859  0.0031183   1.182   0.2391    \n",
       "---\n",
       "Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1\n",
       "\n",
       "(Dispersion parameter for gaussian family taken to be 0.01236245)\n",
       "\n",
       "    Null deviance: 1.921  on 152  degrees of freedom\n",
       "Residual deviance: 1.842  on 149  degrees of freedom\n",
       "AIC: -232\n",
       "\n",
       "Number of Fisher Scoring iterations: 2\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "             (Intercept) great_circle_distance_km              clades_same \n",
       "             0.565963186             -0.001074677             -0.004478218 \n",
       "                 Ct_diff \n",
       "             0.003685932 \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Analysis of Deviance Table\n",
       "\n",
       "Model: gaussian, link: identity\n",
       "\n",
       "Response: prop_snvs_shared\n",
       "\n",
       "Terms added sequentially (first to last)\n",
       "\n",
       "\n",
       "                         Df Deviance Resid. Df Resid. Dev Pr(>Chi)  \n",
       "NULL                                       152     1.9210           \n",
       "great_circle_distance_km  1 0.060703       151     1.8603   0.0267 *\n",
       "clades_same               1 0.001011       150     1.8593   0.7749  \n",
       "Ct_diff                   1 0.017272       149     1.8420   0.2372  \n",
       "---\n",
       "Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# evaluate the proportion of variants shared as a linear combination of divergence and whether the clade is the same\n",
    "%R -i df\n",
    "%R model.marsh = glm(prop_snvs_shared~great_circle_distance_km+clades_same+Ct_diff,data=df,family = gaussian(link=\"identity\"),na.action(na.omit))\n",
    "%R print(summary(model.marsh))\n",
    "%R print(coef(model.marsh))\n",
    "%R print(anova(model.marsh, test=\"Chisq\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LHM-basics (python3)",
   "language": "python",
   "name": "lhm-basics"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
