{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Examine the effects of geography and divergence on proportion of variants shared among samples \n",
    "\n",
    "June 24, 2020 \n",
    "\n",
    "We would like to determine whether samples collected in the same geographic area share more variants than expected by chance alone. In addition to the permutation test, I would also like to perform some sort of metric for whether being close together on the tree also predicts having shared variation. There are probably a few different ways to do this: \n",
    "\n",
    "1. Compare some sort of raw measure of sequence divergence, like hamming distance (number of differences/length of sequence)\n",
    "2. Compare the branch length of the path between the 2 sequences. \n",
    "3. Compare the tmrca, where more divergent sequences will have older tmrcas.\n",
    "\n",
    "All 3 of these could be proxies for how close together sequences are on the tree. It would be good to test this out using the Wisconsin-only build as well as the Wisconsin-focused build with other sequences in there for context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The rpy2.ipython extension is already loaded. To reload it, use:\n",
      "  %reload_ext rpy2.ipython\n"
     ]
    }
   ],
   "source": [
    "import imp\n",
    "import importlib, json\n",
    "import glob\n",
    "import re,copy,json\n",
    "import Bio.Phylo\n",
    "import requests\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "\n",
    "import copy\n",
    "from scipy.special import binom\n",
    "import datetime as dt\n",
    "    \n",
    "import rpy2\n",
    "%load_ext rpy2.ipython\n",
    "\n",
    "# for this to work, you will need to download the most recent version of baltic, available here \n",
    "bt = imp.load_source('baltic', '/Users/lmoncla/src/baltic/baltic/baltic.py')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read in metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_metadata_dict(metadata_file):\n",
    "    x = {}\n",
    "    with open(metadata_file, \"r\") as infile: \n",
    "        for line in infile:\n",
    "            if \"Barcode\" not in line:   # skip first line\n",
    "                samplename = line.split(\"\\t\")[0]\n",
    "                strain_name = samplename.replace(\"hCoV-19/\",\"\")\n",
    "                geo = line.split(\"\\t\")[7].title()\n",
    "                Ct1 = line.split(\"\\t\")[21]\n",
    "                Ct2 = line.split(\"\\t\")[22]\n",
    "                household = line.split(\"\\t\")[29]\n",
    "                \n",
    "                if geo == \"Oregon\":\n",
    "                    geo = \"Oregon WI\"\n",
    "                if geo == \"Columbus\":\n",
    "                    geo = \"Columbus WI\"\n",
    "                if geo == \"Verona\":\n",
    "                    geo = \"Verona WI\"\n",
    "\n",
    "                x[strain_name] = {\"location\":geo, \"Ct1\":Ct1, \"Ct2\": Ct2, \"household\":household}\n",
    "    \n",
    "    return(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in VCF data and output SNVs to query into a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_list_of_vcfs(vcf_directory):\n",
    "    vcf_list = []\n",
    "    for f in glob.glob(vcf_directory + \"*intersection.csv\"):\n",
    "        vcf_list.append(f)\n",
    "    return(vcf_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_in_intersection_snvs(vcf_list, vcf_directory):\n",
    "    within_host_df = pd.DataFrame()\n",
    "    \n",
    "    for v in vcf_list:\n",
    "        # pull out sampleid\n",
    "        sampleid = v.replace(vcf_directory,\"\").replace(\"intersection.csv\",\"\")\n",
    "        \n",
    "        d = pd.read_csv(v, sep=\"\\t\")\n",
    "        d['sampleid'] = sampleid\n",
    "        within_host_df = within_host_df.append(d)\n",
    "        \n",
    "    return(within_host_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {},
   "outputs": [],
   "source": [
    "def separate_snvs_from_frameshift(within_host_df):\n",
    "    snvs_df = within_host_df[(within_host_df['annotation'] == \"missense\") | (within_host_df['annotation'] == \"synonymous\") | (within_host_df['annotation'] == \"stop\")]\n",
    "    snvs_df['aa_site'] = snvs_df['aa_chage'].str[3:-3]\n",
    "    snvs_df['wt_aa'] = snvs_df['aa_chage'].str[0:3]\n",
    "    snvs_df['mut_aa'] = snvs_df['aa_chage'].str[-3:]\n",
    "    \n",
    "    # add in columns for nucleotide changes \n",
    "    snvs_df['nt_ref'] = snvs_df['nt_change'].str.split(\">\",expand=True)[0].str[-1:]\n",
    "    snvs_df['nt_mut'] = snvs_df['nt_change'].str.split(\">\",expand=True)[1]\n",
    "    \n",
    "    indels_df = within_host_df[(within_host_df['annotation'] == \"frameshift\") | (within_host_df['annotation'] == \"frameshift&stop\")]\n",
    "    return(snvs_df, indels_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_strain_names_from_csv(strain_names_file):\n",
    "    strain_names_dict = {}\n",
    "    \n",
    "    with open(strain_names_file, \"r\") as infile: \n",
    "        for line in infile:\n",
    "            if \"Sample identifier\" not in line:\n",
    "                tube_number = line.split(\"\\t\")[1]\n",
    "                strain_name = line.split(\"\\t\")[0].replace(\"hCoV-19/\",\"\")\n",
    "                \n",
    "                # there are 2 sets of tube numbers, some with leading 0s and others without. I am pretty sure we\n",
    "                # want the ones with leading 0s; there are also some we don't want that have non-numeric tube #s\n",
    "                if tube_number.isdigit() and tube_number.startswith(\"0\"):\n",
    "                    strain_names_dict[str(int(tube_number))] = strain_name\n",
    "                    \n",
    "    return(strain_names_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_number_to_strain(sampleid, strain_names_dict):\n",
    "    if sampleid in strain_names_dict:\n",
    "        strain_name = strain_names_dict[sampleid]\n",
    "    else:\n",
    "        strain_name = \"unknown\"\n",
    "        print(sampleid)\n",
    "    return(strain_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_in_strain_column(df, strain_names_dict):\n",
    "    temp_df = pd.DataFrame(df)\n",
    "    strain_name = temp_df['sampleid'].apply(convert_number_to_strain, args=[strain_names_dict])\n",
    "    #strain_name = temp_df['sampleid'].apply(lambda x: \"USA/\" + tube_number_conversion[x] + \"/2020\")\n",
    "    temp_df[\"strain_name\"] = strain_name\n",
    "    return(temp_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_indels(row):\n",
    "    \n",
    "    if \"dup\" in row['nt_change']:\n",
    "        split_char = \"dup\"\n",
    "        variant = row['nt_change'].split(split_char)[1]\n",
    "        new_value = \"-\" + str(int(row[\"POS\"])) + variant\n",
    "    \n",
    "    elif \"del\" in row['nt_change']:\n",
    "        split_char = \"del\"\n",
    "        variant = row['nt_change'].split(split_char)[1]\n",
    "        new_value = str(int(row['POS'])) +  variant + \"-\"\n",
    "    \n",
    "    return(new_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_indel_type(row):\n",
    "    \n",
    "    if \"dup\" in row['nt_change']:\n",
    "        type_change = \"insertion\"\n",
    "     \n",
    "    elif \"del\" in row['nt_change']:\n",
    "        type_change = \"deletion\"\n",
    "    \n",
    "    return(type_change)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_shared_variant_proportion(sample1,sample2,df):\n",
    "    shared_variants = 0\n",
    "    \n",
    "    s1_df = df[df['strain_name'] == sample1]\n",
    "    variants_in_s1 = set(s1_df['nuc_muts'].tolist())\n",
    "    \n",
    "    s2_df = df[df['strain_name'] == sample2]\n",
    "    variants_in_s2 = set(s2_df['nuc_muts'].tolist())\n",
    "    \n",
    "    total_variants = len(variants_in_s1) + len(variants_in_s2)\n",
    "    \n",
    "    for v in variants_in_s1:\n",
    "        if v in variants_in_s2:\n",
    "            shared_variants += 2\n",
    "            \n",
    "    proportion_shared = float(shared_variants/total_variants)\n",
    "            \n",
    "    return(proportion_shared)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in vcfs and convert to dataframes \n",
    "\n",
    "I will only read in the intersection SNVs, meaning the ones that were detected in both technical sequencing replicates. This code will separate this into 2 dataframes, 1 for SNVs and 1 for indels, and will also look up and add in the strain names (necessary for converting from tube numbers, which is how the csvs are labelled)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 484,
   "metadata": {},
   "outputs": [],
   "source": [
    "strain_names_file = \"/Users/lmoncla/src/ncov-WI-within-host/data/spreadsheet-with-strain-names.tsv\"\n",
    "strain_names_dict = read_strain_names_from_csv(strain_names_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 485,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lmoncla/anaconda/envs/LHM-basics/lib/python3.7/site-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/Users/lmoncla/anaconda/envs/LHM-basics/lib/python3.7/site-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  after removing the cwd from sys.path.\n",
      "/Users/lmoncla/anaconda/envs/LHM-basics/lib/python3.7/site-packages/ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"\n",
      "/Users/lmoncla/anaconda/envs/LHM-basics/lib/python3.7/site-packages/ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "/Users/lmoncla/anaconda/envs/LHM-basics/lib/python3.7/site-packages/ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if __name__ == '__main__':\n"
     ]
    }
   ],
   "source": [
    "vcf_directory = \"/Users/lmoncla/src/ncov-WI-within-host/data/VCFs/\"\n",
    "vcfs = return_list_of_vcfs(vcf_directory)\n",
    "all_intersection_variants = read_in_intersection_snvs(vcfs, vcf_directory)\n",
    "all_intersection_variants = add_in_strain_column(all_intersection_variants, strain_names_dict)\n",
    "snvs_only, indels_only = separate_snvs_from_frameshift(all_intersection_variants)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 486,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lmoncla/anaconda/envs/LHM-basics/lib/python3.7/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "# add in a column for the nucleotide mutation so that it is in the same format as the annotation on nextstrain\n",
    "snvs_only['nuc_muts'] = snvs_only['nt_ref'] + snvs_only[\"POS\"].astype(int).astype(str) + snvs_only['nt_mut']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 487,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lmoncla/anaconda/envs/LHM-basics/lib/python3.7/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "/Users/lmoncla/anaconda/envs/LHM-basics/lib/python3.7/site-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>SNP</th>\n",
       "      <th>POS</th>\n",
       "      <th>REF</th>\n",
       "      <th>annotation</th>\n",
       "      <th>gene_x</th>\n",
       "      <th>nt_change</th>\n",
       "      <th>aa_chage</th>\n",
       "      <th>rep1_percent</th>\n",
       "      <th>rep2_percent</th>\n",
       "      <th>%</th>\n",
       "      <th>sampleid</th>\n",
       "      <th>strain_name</th>\n",
       "      <th>nuc_muts</th>\n",
       "      <th>type_mut</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>ORF1ab_875dupA_Leu293fs_frameshift</td>\n",
       "      <td>1135.0</td>\n",
       "      <td>G</td>\n",
       "      <td>frameshift</td>\n",
       "      <td>ORF1ab</td>\n",
       "      <td>875dupA</td>\n",
       "      <td>Leu293fs</td>\n",
       "      <td>2.23</td>\n",
       "      <td>1.96</td>\n",
       "      <td>2.095</td>\n",
       "      <td>117</td>\n",
       "      <td>USA/WI-UW-110/2020</td>\n",
       "      <td>-1135A</td>\n",
       "      <td>insertion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>ORF1ab_6435dupT_Leu2146fs_frameshift</td>\n",
       "      <td>6696.0</td>\n",
       "      <td>C</td>\n",
       "      <td>frameshift</td>\n",
       "      <td>ORF1ab</td>\n",
       "      <td>6435dupT</td>\n",
       "      <td>Leu2146fs</td>\n",
       "      <td>6.63</td>\n",
       "      <td>7.57</td>\n",
       "      <td>7.100</td>\n",
       "      <td>117</td>\n",
       "      <td>USA/WI-UW-110/2020</td>\n",
       "      <td>-6696T</td>\n",
       "      <td>insertion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>8</td>\n",
       "      <td>ORF1ab_10817dupT_Leu3606fs_frameshift</td>\n",
       "      <td>11074.0</td>\n",
       "      <td>C</td>\n",
       "      <td>frameshift</td>\n",
       "      <td>ORF1ab</td>\n",
       "      <td>10817dupT</td>\n",
       "      <td>Leu3606fs</td>\n",
       "      <td>2.67</td>\n",
       "      <td>3.02</td>\n",
       "      <td>2.845</td>\n",
       "      <td>117</td>\n",
       "      <td>USA/WI-UW-110/2020</td>\n",
       "      <td>-11074T</td>\n",
       "      <td>insertion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>17</td>\n",
       "      <td>ORF1ab_15705dupT_Val5236fs_frameshift</td>\n",
       "      <td>15965.0</td>\n",
       "      <td>G</td>\n",
       "      <td>frameshift</td>\n",
       "      <td>ORF1ab</td>\n",
       "      <td>15705dupT</td>\n",
       "      <td>Val5236fs</td>\n",
       "      <td>6.31</td>\n",
       "      <td>5.98</td>\n",
       "      <td>6.145</td>\n",
       "      <td>117</td>\n",
       "      <td>USA/WI-UW-110/2020</td>\n",
       "      <td>-15965T</td>\n",
       "      <td>insertion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>18</td>\n",
       "      <td>ORF1ab_18109dupT_Ser6037fs_frameshift</td>\n",
       "      <td>18368.0</td>\n",
       "      <td>G</td>\n",
       "      <td>frameshift</td>\n",
       "      <td>ORF1ab</td>\n",
       "      <td>18109dupT</td>\n",
       "      <td>Ser6037fs</td>\n",
       "      <td>5.92</td>\n",
       "      <td>4.22</td>\n",
       "      <td>5.070</td>\n",
       "      <td>117</td>\n",
       "      <td>USA/WI-UW-110/2020</td>\n",
       "      <td>-18368T</td>\n",
       "      <td>insertion</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Unnamed: 0                                    SNP      POS REF  \\\n",
       "0            1     ORF1ab_875dupA_Leu293fs_frameshift   1135.0   G   \n",
       "3            4   ORF1ab_6435dupT_Leu2146fs_frameshift   6696.0   C   \n",
       "5            8  ORF1ab_10817dupT_Leu3606fs_frameshift  11074.0   C   \n",
       "12          17  ORF1ab_15705dupT_Val5236fs_frameshift  15965.0   G   \n",
       "13          18  ORF1ab_18109dupT_Ser6037fs_frameshift  18368.0   G   \n",
       "\n",
       "    annotation  gene_x  nt_change   aa_chage  rep1_percent  rep2_percent  \\\n",
       "0   frameshift  ORF1ab    875dupA   Leu293fs          2.23          1.96   \n",
       "3   frameshift  ORF1ab   6435dupT  Leu2146fs          6.63          7.57   \n",
       "5   frameshift  ORF1ab  10817dupT  Leu3606fs          2.67          3.02   \n",
       "12  frameshift  ORF1ab  15705dupT  Val5236fs          6.31          5.98   \n",
       "13  frameshift  ORF1ab  18109dupT  Ser6037fs          5.92          4.22   \n",
       "\n",
       "        % sampleid         strain_name nuc_muts   type_mut  \n",
       "0   2.095      117  USA/WI-UW-110/2020   -1135A  insertion  \n",
       "3   7.100      117  USA/WI-UW-110/2020   -6696T  insertion  \n",
       "5   2.845      117  USA/WI-UW-110/2020  -11074T  insertion  \n",
       "12  6.145      117  USA/WI-UW-110/2020  -15965T  insertion  \n",
       "13  5.070      117  USA/WI-UW-110/2020  -18368T  insertion  "
      ]
     },
     "execution_count": 487,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# add a column with formatted indel that matches nextstrain\n",
    "indels_only['nuc_muts'] = indels_only.apply(format_indels, axis=1)\n",
    "indels_only['type_mut'] = indels_only.apply(return_indel_type, axis=1)\n",
    "indels_only.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 488,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into only low frequency, here defined as <50%; I don't really want to query the fixed variants here \n",
    "low_freq_snvs_only = snvs_only[snvs_only[\"%\"] < 50]\n",
    "low_freq_indels_only = indels_only[indels_only[\"%\"] < 50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 489,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "59\n",
      "31\n",
      "90\n"
     ]
    }
   ],
   "source": [
    "snvs_to_query = set(low_freq_snvs_only['nuc_muts'])\n",
    "indels_to_query = set(low_freq_indels_only['nuc_muts'])\n",
    "all_variants_to_query = snvs_to_query.copy()\n",
    "all_variants_to_query.update(indels_to_query)\n",
    "print(len(snvs_to_query))\n",
    "print(len(indels_to_query))\n",
    "print(len(all_variants_to_query))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code for parsing through tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"This is a small, recursive function to return the TMRCA for 2 tips. Starting with the parental node of tip1,\n",
    "go recursively backwards in the tree until you find an internal node whose children contains both tip1 and \n",
    "tip2. Return that node.\"\"\"\n",
    "\n",
    "def return_TMRCA_node(input_node,tip1,tip2):\n",
    "    \n",
    "    # for a given internal node, generate a list of all its children, i.e., tips descending from that node\n",
    "    node = input_node\n",
    "    children = list(node.children)   # .children will output all of the direct descendants as baltic objects\n",
    "    leaves = list(node.leaves)       # .leaves will output the names of all tips descending from the node\n",
    "    \n",
    "    if tip2 in leaves and tip1 in leaves: \n",
    "        node_to_return = node\n",
    "    else:\n",
    "        node_to_return = return_TMRCA_node(node.parent,tip1,tip2)\n",
    "            \n",
    "    return(node_to_return)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"given 2 tips and a tree, iterate through the tree. when we reach tip 1, run return_TMRCA_node, to find the \n",
    "internal node that is the TMRCA for tips 1 and 2. Extract its date and return the node object and date\"\"\"\n",
    "\n",
    "def return_TMRCA(tip1,tip2,tree):\n",
    "    for k in tree.Objects: \n",
    "        if k.branchType == \"leaf\" and k.name == tip1:\n",
    "            tmrca_node = return_TMRCA_node(k.parent,tip1,tip2)\n",
    "            date = tmrca_node.traits['node_attrs']['num_date']['value']  # output the mean inferred date\n",
    "            \n",
    "    return(tmrca_node, date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Given a starting internal node, and a tip you would like to end at, traverse the full path from that node to\n",
    "tip. Along the way, gather nucleotide mutations that occur along that path. Once you have reached the ending \n",
    "tip, return the list of mutations that fell along that path\"\"\"\n",
    "\n",
    "def return_divergence_on_path_to_tip(starting_node, ending_tip):\n",
    "    \n",
    "    children = starting_node.children\n",
    "    \n",
    "    for child in children:\n",
    "        \n",
    "        \"\"\"if the child is a leaf: if leaf is the target end tip, collect its divergence and return; \n",
    "        if leaf is not the target end tip, move on\"\"\"\n",
    "        \"\"\"if the child is an internal node: first, test whether that child node contains the target tips in its \n",
    "        children. child.leaves will output a list of the names of all tips descending from that node. If not, pass. \n",
    "        if the node does contain the target end tip in its leaves, keep traversing down that node recursively\"\"\"\n",
    "\n",
    "        if child.branchType == \"leaf\":\n",
    "            if child.name != ending_tip:\n",
    "                pass\n",
    "            elif child.name == ending_tip:\n",
    "                child_divergence = child.traits['node_attrs']['div']\n",
    "                return(child_divergence)\n",
    "         \n",
    "        elif child.branchType == \"node\":\n",
    "            if ending_tip not in child.leaves:\n",
    "                pass\n",
    "            else:\n",
    "                child_divergence = return_divergence_on_path_to_tip(child, ending_tip)\n",
    "    \n",
    "    return(child_divergence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_clade(tipname, tree):\n",
    "    for k in tree.Objects:\n",
    "        if k.branchType == \"leaf\" and k.name == tipname:\n",
    "            clade = k.traits['node_attrs']['clade_membership']['value']\n",
    "    return(clade)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_all_Wisconsin_tips(tree):\n",
    "    Wisconsin_leaves = []\n",
    "    \n",
    "    for k in tree.Objects: \n",
    "        if k.branchType == \"leaf\":\n",
    "            division = k.traits['node_attrs']['division']['value']\n",
    "            if division == \"Wisconsin\":\n",
    "                Wisconsin_leaves.append(k.name)\n",
    "                \n",
    "    return(Wisconsin_leaves)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_Cts(tip1,tip2,metadata):\n",
    "        \n",
    "    mean1 = (float(metadata[tip1]['Ct1']))\n",
    "    mean2 = (float(metadata[tip2]['Ct1']))\n",
    "    difference = abs(mean1-mean2)\n",
    "    return(difference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_location(tip1,tip2,metadata):\n",
    "    geo1 = metadata[tip1][\"location\"]\n",
    "    geo2 = metadata[tip2][\"location\"]\n",
    "    \n",
    "    if geo1 == geo2: \n",
    "        location = 1\n",
    "    else: \n",
    "        location = 0\n",
    "        \n",
    "    return(location,geo1,geo2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_lat_longs_dictionary(lat_longs_file):\n",
    "    \n",
    "    output_dict = {}\n",
    "    \n",
    "    with open(lat_longs_file, \"r\") as infile: \n",
    "        for line in infile:\n",
    "            if len(line.split(\"\\t\")) == 4:\n",
    "                location = line.split(\"\\t\")[1]\n",
    "                longitude = line.split(\"\\t\")[2]\n",
    "                latitude = line.split(\"\\t\")[3].strip()\n",
    "                output_dict[location] = {\"latitude\":latitude, \"longitude\":longitude}\n",
    "    return(output_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"I took this from here, https://stackoverflow.com/questions/4913349/haversine-formula-in-python-bearing-and-distance-between-two-gps-points\n",
    "A decent overview of this formula can be found here: https://www.movable-type.co.uk/scripts/latlong.html\"\"\"\n",
    "from math import radians, cos, sin, asin, sqrt\n",
    "\n",
    "def haversine(lon1, lat1, lon2, lat2):\n",
    "    \"\"\"\n",
    "    Calculate the great circle distance between two points \n",
    "    on the earth (specified in decimal degrees). \n",
    "    \"\"\"\n",
    "    # convert decimal degrees to radians \n",
    "    lon1, lat1, lon2, lat2 = map(radians, [lon1, lat1, lon2, lat2])\n",
    "\n",
    "    # haversine formula \n",
    "    dlon = lon2 - lon1 \n",
    "    dlat = lat2 - lat1 \n",
    "    a = sin(dlat/2)**2 + cos(lat1) * cos(lat2) * sin(dlon/2)**2\n",
    "    c = 2 * asin(sqrt(a)) \n",
    "    r = 6371 # Radius of earth in kilometers. Use 3956 for miles\n",
    "    return c * r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 481,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_distance_between_locations(tip1,tip2,metadata,lat_longs):\n",
    "    geo1 = metadata[tip1][\"location\"]\n",
    "    geo2 = metadata[tip2][\"location\"]\n",
    "    \n",
    "    lat1 = lat_longs_dict[geo1]['latitude']\n",
    "    lat2 = lat_longs_dict[geo2]['latitude']\n",
    "    \n",
    "    long1 = lat_longs_dict[geo1]['longitude']\n",
    "    long2 = lat_longs_dict[geo2]['longitude']\n",
    "    \n",
    "    distance_km = haversine(float(long1), float(lat1), float(long2), float(lat2))\n",
    "    return(distance_km)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# run!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test this out first on the Wisconsin-only build json\n",
    "#WI_tree_path = \"/Users/lmoncla/src/ncov-WI-within-host/data/Wisconsin.json\"\n",
    "WI_tree_path = \"/Volumes/gradschool-and-postdoc-backups/post-doc/stored_files_too_big_for_laptop/ncov-build-forced-WI/ncov/auspice/ncov_usa_wisconsin.json\"\n",
    "\n",
    "analysis_level = \"division\"\n",
    "\n",
    "# with open(WI_tree_path) as json_file:\n",
    "#     WI_tree_json = json.load(json_file)\n",
    "# WI_tree_object=WI_tree_json['tree']\n",
    "# WI_meta=WI_tree_json['meta']\n",
    "# json_translation={'absoluteTime':lambda k: k.traits['node_attrs']['num_date']['value'],'name':'name'} ## allows baltic to find correct attributes in JSON, height and name are required at a minimum\n",
    "# json_meta={'file':WI_meta,'traitName':analysis_level} ## if you want auspice stylings you can import the meta file used on nextstrain.org\n",
    "\n",
    "# WI_tree=bt.loadJSON(WI_tree_object,json_translation,json_meta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 490,
   "metadata": {},
   "outputs": [],
   "source": [
    "transmission_pairs = [[\"USA/WI-UW-65/2020\",\"USA/WI-UW-32/2020\"],[\"USA/WI-UW-41/2020\",\"USA/WI-UW-48/2020\"],\n",
    "                      [\"USA/WI-UW-74/2020\",\"USA/WI-UW-29/2020\"],[\"USA/WI-UW-120/2020\",\"USA/WI-UW-119/2020\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 491,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "369\n"
     ]
    }
   ],
   "source": [
    "Wisconsin_tips_in_tree = return_all_Wisconsin_tips(WI_tree)\n",
    "print(len(Wisconsin_tips_in_tree))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 492,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "USA/WI-UW-119/2020\n",
      "19\n"
     ]
    }
   ],
   "source": [
    "tips_to_query = set(all_intersection_variants['strain_name'].tolist())\n",
    "\n",
    "for t in tips_to_query:\n",
    "    if t not in Wisconsin_tips_in_tree:\n",
    "        print(t)\n",
    "        \n",
    "print(len(tips_to_query))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 493,
   "metadata": {},
   "outputs": [],
   "source": [
    "tips_to_query.remove(\"USA/WI-UW-119/2020\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 494,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in metadata and latitude and longitude files\n",
    "metadata_input_file = \"/Users/lmoncla/src/ncov-WI-within-host/data/spreadsheet-with-strain-names.tsv\"\n",
    "metadata_dict = return_metadata_dict(metadata_input_file)\n",
    "lat_longs_dict = return_lat_longs_dictionary(\"/Users/lmoncla/src/ncov/config/lat_longs.tsv\")\n",
    "wh_df_to_use = low_freq_snvs_only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 495,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame()\n",
    "\n",
    "combos = []\n",
    "for t in tips_to_query: \n",
    "    tip1 = t\n",
    "    \n",
    "    for a in tips_to_query:\n",
    "        tip2 = a\n",
    "        combo = set([tip1,tip2])\n",
    "        \n",
    "        if tip1 != tip2 and combo not in combos:   # to prevent doing the pairwise comparisons twice\n",
    "            \n",
    "            # output Cts\n",
    "            Ct_diff = compare_Cts(tip1,tip2,metadata_dict)\n",
    "            \n",
    "            # are the locations the same? 0 means no, 1 means yes\n",
    "            location,loc1,loc2 = compare_location(tip1,tip2,metadata_dict)\n",
    "            \n",
    "            # output great circle distance between locations\n",
    "            great_circle_distance = return_distance_between_locations(tip1,tip2,metadata_dict,lat_longs_dict)\n",
    "\n",
    "            # output their clades\n",
    "            tip1_clade = return_clade(tip1, tree)\n",
    "            tip2_clade = return_clade(tip2, tree)\n",
    "            if tip1_clade == tip2_clade:\n",
    "                clades_same = 0\n",
    "            else:\n",
    "                clades_same = 1\n",
    "\n",
    "            # output the tmrca and divergence\n",
    "            parental_node,tmrca_date = return_TMRCA(tip1,tip2,tree)\n",
    "            parent_divergence = parental_node.traits['node_attrs']['div']\n",
    "\n",
    "            tip1_divergence = return_divergence_on_path_to_tip(parental_node, tip1)\n",
    "            tip2_divergence = return_divergence_on_path_to_tip(parental_node, tip2)\n",
    "\n",
    "            node_to_tip1 = tip1_divergence - parent_divergence\n",
    "            node_to_tip2 = tip2_divergence - parent_divergence\n",
    "            total_divergence = node_to_tip1 + node_to_tip2\n",
    "\n",
    "            # calculate the proportion of variants shared\n",
    "            shared_proportion_snvs = compute_shared_variant_proportion(tip1,tip2,wh_df_to_use)\n",
    "\n",
    "            d = pd.DataFrame.from_dict({\"tip1\":[tip1],\"tip2\":[tip2],\"tmrca\":[tmrca_date],\"clades_same\":[clades_same],\n",
    "                                        \"divergence\":[total_divergence],\"prop_snvs_shared\":[shared_proportion_snvs],\n",
    "                                       \"Ct_diff\":[Ct_diff], \"location_same\":[location],\"location1\":[loc1],\"location2\":[loc2],\n",
    "                                       \"great_circle_distance_km\":[great_circle_distance]})\n",
    "\n",
    "            df = df.append(d)\n",
    "            combos.append(combo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 496,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "153"
      ]
     },
     "execution_count": 496,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 471,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write to csv so I can use it in R \n",
    "df.to_csv(\"WI-variants-vs-geo-2020-06-29.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First, evaluate divergence \n",
    "\n",
    "I will first model shared diversity as a function of divergence. I will then model it as a combination of divergence, Ct differences and having the same clade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 503,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "Call:\n",
       "glm(formula = prop_snvs_shared ~ divergence, family = gaussian(link = \"identity\"), \n",
       "    data = df, weights = na.action(na.omit))\n",
       "\n",
       "Deviance Residuals: \n",
       "     Min        1Q    Median        3Q       Max  \n",
       "-0.18871  -0.08327  -0.02562   0.08551   0.27621  \n",
       "\n",
       "Coefficients:\n",
       "             Estimate Std. Error t value Pr(>|t|)    \n",
       "(Intercept)  0.588810   0.016950  34.738   <2e-16 ***\n",
       "divergence  -0.003827   0.001697  -2.256   0.0255 *  \n",
       "---\n",
       "Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1\n",
       "\n",
       "(Dispersion parameter for gaussian family taken to be 0.01230708)\n",
       "\n",
       "    Null deviance: 1.9210  on 152  degrees of freedom\n",
       "Residual deviance: 1.8584  on 151  degrees of freedom\n",
       "AIC: -234.65\n",
       "\n",
       "Number of Fisher Scoring iterations: 2\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# evaluate the proportion of variants shared as a function of divergence\n",
    "%R -i df\n",
    "%R model.div = glm(prop_snvs_shared~divergence,data=df,family = gaussian(link=\"identity\"),na.action(na.omit))\n",
    "%R print(summary(model.div))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 504,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "Call:\n",
       "glm(formula = prop_snvs_shared ~ great_circle_distance_km, family = gaussian(link = \"identity\"), \n",
       "    data = df, weights = na.action(na.omit))\n",
       "\n",
       "Deviance Residuals: \n",
       "     Min        1Q    Median        3Q       Max  \n",
       "-0.18069  -0.08377  -0.01599   0.07603   0.28099  \n",
       "\n",
       "Coefficients:\n",
       "                           Estimate Std. Error t value Pr(>|t|)    \n",
       "(Intercept)               0.5814392  0.0144260   40.30   <2e-16 ***\n",
       "great_circle_distance_km -0.0011886  0.0005355   -2.22   0.0279 *  \n",
       "---\n",
       "Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1\n",
       "\n",
       "(Dispersion parameter for gaussian family taken to be 0.01231979)\n",
       "\n",
       "    Null deviance: 1.9210  on 152  degrees of freedom\n",
       "Residual deviance: 1.8603  on 151  degrees of freedom\n",
       "AIC: -234.49\n",
       "\n",
       "Number of Fisher Scoring iterations: 2\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Analysis of Deviance Table\n",
       "\n",
       "Model: gaussian, link: identity\n",
       "\n",
       "Response: prop_snvs_shared\n",
       "\n",
       "Terms added sequentially (first to last)\n",
       "\n",
       "\n",
       "                         Df Deviance Resid. Df Resid. Dev Pr(>Chi)  \n",
       "NULL                                       152     1.9210           \n",
       "great_circle_distance_km  1 0.060703       151     1.8603  0.02644 *\n",
       "---\n",
       "Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# evaluate the proportion of variants shared as a function of great circle distance\n",
    "%R -i df\n",
    "%R model.div2 = glm(prop_snvs_shared~great_circle_distance_km,data=df,family = gaussian(link=\"identity\"),na.action(na.omit))\n",
    "%R print(summary(model.div2))\n",
    "%R print(anova(model.div2, test=\"Chisq\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 505,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "Call:\n",
       "glm(formula = prop_snvs_shared ~ Ct_diff, family = gaussian(link = \"identity\"), \n",
       "    data = df, weights = na.action(na.omit))\n",
       "\n",
       "Deviance Residuals: \n",
       "     Min        1Q    Median        3Q       Max  \n",
       "-0.18003  -0.08808  -0.01884   0.07686   0.29479  \n",
       "\n",
       "Coefficients:\n",
       "            Estimate Std. Error t value Pr(>|t|)    \n",
       "(Intercept) 0.536954   0.016301  32.939   <2e-16 ***\n",
       "Ct_diff     0.004464   0.003117   1.432    0.154    \n",
       "---\n",
       "Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1\n",
       "\n",
       "(Dispersion parameter for gaussian family taken to be 0.01255129)\n",
       "\n",
       "    Null deviance: 1.9210  on 152  degrees of freedom\n",
       "Residual deviance: 1.8952  on 151  degrees of freedom\n",
       "AIC: -231.64\n",
       "\n",
       "Number of Fisher Scoring iterations: 2\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Analysis of Deviance Table\n",
       "\n",
       "Model: gaussian, link: identity\n",
       "\n",
       "Response: prop_snvs_shared\n",
       "\n",
       "Terms added sequentially (first to last)\n",
       "\n",
       "\n",
       "        Df Deviance Resid. Df Resid. Dev Pr(>Chi)\n",
       "NULL                      152     1.9210         \n",
       "Ct_diff  1 0.025747       151     1.8952   0.1521\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# evaluate the proportion of variants shared as a function of Ct difference\n",
    "%R -i df\n",
    "%R model.div2 = glm(prop_snvs_shared~Ct_diff,data=df,family = gaussian(link=\"identity\"),na.action(na.omit))\n",
    "%R print(summary(model.div2))\n",
    "%R print(anova(model.div2, test=\"Chisq\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 506,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "Call:\n",
       "glm(formula = prop_snvs_shared ~ clades_same, family = gaussian(link = \"identity\"), \n",
       "    data = df, weights = na.action(na.omit))\n",
       "\n",
       "Deviance Residuals: \n",
       "     Min        1Q    Median        3Q       Max  \n",
       "-0.18762  -0.09554  -0.01675   0.07492   0.28325  \n",
       "\n",
       "Coefficients:\n",
       "            Estimate Std. Error t value Pr(>|t|)    \n",
       "(Intercept)  0.56857    0.01559  36.462   <2e-16 ***\n",
       "clades_same -0.01849    0.01919  -0.963    0.337    \n",
       "---\n",
       "Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1\n",
       "\n",
       "(Dispersion parameter for gaussian family taken to be 0.01264407)\n",
       "\n",
       "    Null deviance: 1.9210  on 152  degrees of freedom\n",
       "Residual deviance: 1.9093  on 151  degrees of freedom\n",
       "AIC: -230.51\n",
       "\n",
       "Number of Fisher Scoring iterations: 2\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Analysis of Deviance Table\n",
       "\n",
       "Model: gaussian, link: identity\n",
       "\n",
       "Response: prop_snvs_shared\n",
       "\n",
       "Terms added sequentially (first to last)\n",
       "\n",
       "\n",
       "            Df Deviance Resid. Df Resid. Dev Pr(>Chi)\n",
       "NULL                          152     1.9210         \n",
       "clades_same  1 0.011737       151     1.9092   0.3353\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# lastly, try with clade same\n",
    "%R -i df\n",
    "%R model.div2 = glm(prop_snvs_shared~clades_same,data=df,family = gaussian(link=\"identity\"),na.action(na.omit))\n",
    "%R print(summary(model.div2))\n",
    "%R print(anova(model.div2, test=\"Chisq\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## now try all together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 507,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "Call:\n",
       "glm(formula = prop_snvs_shared ~ divergence + clades_same + Ct_diff + \n",
       "    great_circle_distance_km, family = gaussian(link = \"identity\"), \n",
       "    data = df, weights = na.action(na.omit))\n",
       "\n",
       "Deviance Residuals: \n",
       "     Min        1Q    Median        3Q       Max  \n",
       "-0.20479  -0.07855  -0.01655   0.08104   0.28272  \n",
       "\n",
       "Coefficients:\n",
       "                           Estimate Std. Error t value Pr(>|t|)    \n",
       "(Intercept)               0.5762230  0.0243430  23.671   <2e-16 ***\n",
       "divergence               -0.0028635  0.0021833  -1.312    0.192    \n",
       "clades_same               0.0093013  0.0225840   0.412    0.681    \n",
       "Ct_diff                   0.0033767  0.0031198   1.082    0.281    \n",
       "great_circle_distance_km -0.0007778  0.0006103  -1.274    0.204    \n",
       "---\n",
       "Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1\n",
       "\n",
       "(Dispersion parameter for gaussian family taken to be 0.01230299)\n",
       "\n",
       "    Null deviance: 1.9210  on 152  degrees of freedom\n",
       "Residual deviance: 1.8208  on 148  degrees of freedom\n",
       "AIC: -231.77\n",
       "\n",
       "Number of Fisher Scoring iterations: 2\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "             (Intercept)               divergence              clades_same \n",
       "            0.5762230400            -0.0028634616             0.0093012867 \n",
       "                 Ct_diff great_circle_distance_km \n",
       "            0.0033767155            -0.0007777859 \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Analysis of Deviance Table\n",
       "\n",
       "Model: gaussian, link: identity\n",
       "\n",
       "Response: prop_snvs_shared\n",
       "\n",
       "Terms added sequentially (first to last)\n",
       "\n",
       "\n",
       "                         Df Deviance Resid. Df Resid. Dev Pr(>Chi)  \n",
       "NULL                                       152     1.9210           \n",
       "divergence                1 0.062623       151     1.8584  0.02406 *\n",
       "clades_same               1 0.001026       150     1.8573  0.77276  \n",
       "Ct_diff                   1 0.016516       149     1.8408  0.24660  \n",
       "great_circle_distance_km  1 0.019983       148     1.8208  0.20250  \n",
       "---\n",
       "Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# evaluate the proportion of variants shared as a linear combination of divergence and whether the clade is the same\n",
    "%R -i df\n",
    "%R model.marsh = glm(prop_snvs_shared~divergence+clades_same+Ct_diff+great_circle_distance_km,data=df,family = gaussian(link=\"identity\"),na.action(na.omit))\n",
    "%R print(summary(model.marsh))\n",
    "%R print(coef(model.marsh))\n",
    "%R print(anova(model.marsh, test=\"Chisq\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 508,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "Call:\n",
       "glm(formula = prop_snvs_shared ~ divergence + clades_same + Ct_diff, \n",
       "    family = gaussian(link = \"identity\"), data = df, weights = na.action(na.omit))\n",
       "\n",
       "Deviance Residuals: \n",
       "     Min        1Q    Median        3Q       Max  \n",
       "-0.19530  -0.08062  -0.02077   0.08819   0.28793  \n",
       "\n",
       "Coefficients:\n",
       "             Estimate Std. Error t value Pr(>|t|)    \n",
       "(Intercept)  0.569131   0.023748  23.965   <2e-16 ***\n",
       "divergence  -0.003896   0.002032  -1.917   0.0571 .  \n",
       "clades_same  0.006918   0.022554   0.307   0.7595    \n",
       "Ct_diff      0.003609   0.003121   1.156   0.2494    \n",
       "---\n",
       "Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1\n",
       "\n",
       "(Dispersion parameter for gaussian family taken to be 0.01235454)\n",
       "\n",
       "    Null deviance: 1.9210  on 152  degrees of freedom\n",
       "Residual deviance: 1.8408  on 149  degrees of freedom\n",
       "AIC: -232.1\n",
       "\n",
       "Number of Fisher Scoring iterations: 2\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       " (Intercept)   divergence  clades_same      Ct_diff \n",
       " 0.569130801 -0.003895600  0.006918280  0.003608546 \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Analysis of Deviance Table\n",
       "\n",
       "Model: gaussian, link: identity\n",
       "\n",
       "Response: prop_snvs_shared\n",
       "\n",
       "Terms added sequentially (first to last)\n",
       "\n",
       "\n",
       "            Df Deviance Resid. Df Resid. Dev Pr(>Chi)  \n",
       "NULL                          152     1.9210           \n",
       "divergence   1 0.062623       151     1.8584  0.02436 *\n",
       "clades_same  1 0.001026       150     1.8573  0.77322  \n",
       "Ct_diff      1 0.016516       149     1.8408  0.24759  \n",
       "---\n",
       "Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# evaluate the proportion of variants shared as a linear combination of divergence and whether the clade is the same\n",
    "%R -i df\n",
    "%R model.marsh = glm(prop_snvs_shared~divergence+clades_same+Ct_diff,data=df,family = gaussian(link=\"identity\"),na.action(na.omit))\n",
    "%R print(summary(model.marsh))\n",
    "%R print(coef(model.marsh))\n",
    "%R print(anova(model.marsh, test=\"Chisq\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 509,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "Call:\n",
       "glm(formula = prop_snvs_shared ~ great_circle_distance_km + clades_same + \n",
       "    Ct_diff, family = gaussian(link = \"identity\"), data = df, \n",
       "    weights = na.action(na.omit))\n",
       "\n",
       "Deviance Residuals: \n",
       "     Min        1Q    Median        3Q       Max  \n",
       "-0.19447  -0.08212  -0.01615   0.07871   0.27799  \n",
       "\n",
       "Coefficients:\n",
       "                           Estimate Std. Error t value Pr(>|t|)    \n",
       "(Intercept)               0.5659632  0.0231075  24.493   <2e-16 ***\n",
       "great_circle_distance_km -0.0010747  0.0005681  -1.892   0.0605 .  \n",
       "clades_same              -0.0044782  0.0200395  -0.223   0.8235    \n",
       "Ct_diff                   0.0036859  0.0031183   1.182   0.2391    \n",
       "---\n",
       "Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1\n",
       "\n",
       "(Dispersion parameter for gaussian family taken to be 0.01236245)\n",
       "\n",
       "    Null deviance: 1.921  on 152  degrees of freedom\n",
       "Residual deviance: 1.842  on 149  degrees of freedom\n",
       "AIC: -232\n",
       "\n",
       "Number of Fisher Scoring iterations: 2\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "             (Intercept) great_circle_distance_km              clades_same \n",
       "             0.565963186             -0.001074677             -0.004478218 \n",
       "                 Ct_diff \n",
       "             0.003685932 \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Analysis of Deviance Table\n",
       "\n",
       "Model: gaussian, link: identity\n",
       "\n",
       "Response: prop_snvs_shared\n",
       "\n",
       "Terms added sequentially (first to last)\n",
       "\n",
       "\n",
       "                         Df Deviance Resid. Df Resid. Dev Pr(>Chi)  \n",
       "NULL                                       152     1.9210           \n",
       "great_circle_distance_km  1 0.060703       151     1.8603   0.0267 *\n",
       "clades_same               1 0.001011       150     1.8593   0.7749  \n",
       "Ct_diff                   1 0.017272       149     1.8420   0.2372  \n",
       "---\n",
       "Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# evaluate the proportion of variants shared as a linear combination of divergence and whether the clade is the same\n",
    "%R -i df\n",
    "%R model.marsh = glm(prop_snvs_shared~great_circle_distance_km+clades_same+Ct_diff,data=df,family = gaussian(link=\"identity\"),na.action(na.omit))\n",
    "%R print(summary(model.marsh))\n",
    "%R print(coef(model.marsh))\n",
    "%R print(anova(model.marsh, test=\"Chisq\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LHM-basics (python3)",
   "language": "python",
   "name": "lhm-basics"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
