{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read in SNV vcfs and output dataframe \n",
    "\n",
    "August 14, 2020\n",
    "\n",
    "I am finding myself needing to read in these intersection vcf files and convert them to a dataframe and copying and pasting all of this code over and over again. Instead, I am going to try making this notebook, where I can do all the coding to return the dataframe I want, and then I can just import this into all the other analysis notebooks where I use this dataframe. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import pandas as pd \n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read in metadata "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_in_clades_file(clades_file):\n",
    "    clades_dict = {}\n",
    "    with open(clades_file, \"r\") as infile:\n",
    "        for line in infile:\n",
    "            strain_name = line.split(\"\\t\")[0]\n",
    "            clade = line.split(\"\\t\")[1].strip()\n",
    "        \n",
    "            clades_dict[strain_name] = clade\n",
    "    return(clades_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_strain_name(samplename):\n",
    "    strain_name = samplename.replace(\"hCoV-19/\",\"\")\n",
    "\n",
    "    if \"USA\" not in strain_name: \n",
    "        strain_name = \"USA/\" + strain_name\n",
    "    if \"/2020\" not in strain_name:\n",
    "        strain_name = strain_name + \"/2020\"\n",
    "        \n",
    "    return(strain_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_metadata_dict(metadata_file, clades_file):\n",
    "    x = {}\n",
    "    clades_dict = read_in_clades_file(clades_file)\n",
    "    \n",
    "    with open(metadata_file, \"r\") as infile: \n",
    "        for line in infile:\n",
    "            if \"Barcode\" not in line:   # skip first line\n",
    "                samplename = line.split(\"\\t\")[0]\n",
    "                strain_name = fix_strain_name(samplename)\n",
    "                geo = line.split(\"\\t\")[8].title()\n",
    "                Ct1 = line.split(\"\\t\")[22]\n",
    "                Ct2 = line.split(\"\\t\")[23]\n",
    "                household = line.split(\"\\t\")[33]\n",
    "                \n",
    "                # read in clade\n",
    "                if strain_name in clades_dict:\n",
    "                    clade = clades_dict[strain_name]\n",
    "                else:\n",
    "                    clade = \"unknown\"\n",
    "                \n",
    "                if geo == \"Oregon\":\n",
    "                    geo = \"Oregon WI\"\n",
    "                if geo == \"Columbus\":\n",
    "                    geo = \"Columbus WI\"\n",
    "                if geo == \"Verona\":\n",
    "                    geo = \"Verona WI\"\n",
    "                if \"Dane\" in geo: \n",
    "                    geo = \"Dane County\"\n",
    "                if geo == \"Columbia County\":\n",
    "                    geo = \"Columbia County WI\"\n",
    "\n",
    "                x[strain_name] = {\"location\":geo, \"Ct1\":Ct1, \"Ct2\": Ct2, \"household\":household, \"clade\":clade}\n",
    "    \n",
    "    return(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The following functions are all for reading in csv iles and formatting into pandas dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_list_of_vcfs(vcf_directory):\n",
    "    vcf_list = []\n",
    "    for f in glob.glob(vcf_directory + \"*intersection.csv\"):\n",
    "        vcf_list.append(f)\n",
    "    return(vcf_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_in_intersection_snvs(vcf_list, vcf_directory):\n",
    "    within_host_df = pd.DataFrame()\n",
    "    samples_without_variants = []\n",
    "    \n",
    "    for v in vcf_list:\n",
    "        # pull out sampleid\n",
    "        sampleid = v.replace(vcf_directory,\"\").replace(\"-intersection.csv\",\"\")\n",
    "        \n",
    "        d = pd.read_csv(v, sep=\"\\t\")\n",
    "        d['sampleid'] = sampleid\n",
    "        if len(d) == 0:\n",
    "            samples_without_variants.append(sampleid)\n",
    "        within_host_df = within_host_df.append(d)\n",
    "        \n",
    "    return(within_host_df, samples_without_variants)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_strain_names_from_csv(strain_names_file):\n",
    "    strain_names_dict = {}\n",
    "    \n",
    "    with open(strain_names_file, \"r\") as infile: \n",
    "        for line in infile:\n",
    "            if \"Sample identifier\" not in line:\n",
    "                tube_number = line.split(\"\\t\")[1]\n",
    "                samplename = line.split(\"\\t\")[0]\n",
    "                strain_name = fix_strain_name(samplename)\n",
    "                hospital_id = line.split(\"\\t\")[2]\n",
    "                \n",
    "                # there are 2 sets of tube numbers, some with leading 0s and others without. I am pretty sure we\n",
    "                # want the ones with leading 0s; there are also some we don't want that have non-numeric tube #s\n",
    "                if tube_number.isdigit() and tube_number.startswith(\"0\"):\n",
    "                    strain_names_dict[str(int(tube_number))] = strain_name\n",
    "               \n",
    "                else:\n",
    "                    # I need to clean up the promega tube numbers as well\n",
    "                    if \"Promega\" in hospital_id: \n",
    "                        new_tube_number = tube_number.replace(\" (from State Lab via Promega)\",\"\").replace(\"nCov-\",\"\") + \"P\"\n",
    "                        strain_names_dict[new_tube_number] = strain_name\n",
    "                    else:\n",
    "                        strain_names_dict[tube_number] = strain_name\n",
    "                            \n",
    "    \n",
    "    return(strain_names_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_snp_column(df):\n",
    "    \n",
    "    # first, clean up the SNP column, which is weirdly formatted when in intergenic regions\n",
    "    df['SNP'] = df['SNP'].str.replace(\"CHR_START\",\"CHRSTART\")\n",
    "    df['SNP'] = df['SNP'].str.replace(\"CHR_END\",\"CHREND\")\n",
    "    df['SNP'] = df['SNP'].str.replace(\"_n.\",\"_\")\n",
    "    df['SNP'] = df['SNP'].str.replace(\"__\",\"_\")\n",
    "    \n",
    "    # separate the SNP column into gene\n",
    "    df['gene'] = df['SNP'].str.split(\"_\", expand=True)[0]\n",
    "    df['nt_change'] = df['SNP'].str.split(\"_\", expand=True)[1]\n",
    "    df['aa_change'] = df['SNP'].str.split(\"_\", expand=True)[2]\n",
    "    df['annotation'] = df['SNP'].str.split(\"_\", expand=True)[3]\n",
    "    \n",
    "    # change % to string\n",
    "    df = df.rename(columns = {'%':'frequency'})\n",
    "    \n",
    "    return(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def separate_snvs(within_host_df):\n",
    "    # first, separate out and format snvs_df\n",
    "    snvs_df = within_host_df[within_host_df['type_of_variant'] == \"snv\"]\n",
    "    \n",
    "    # the final fine and replaces are to fix the intergenic-region annotations\n",
    "    snvs_df['aa_site'] = snvs_df['aa_change'].str[3:-3].str.replace(\"ergenic-reg\",\"NA\")\n",
    "    snvs_df['wt_aa'] = snvs_df['aa_change'].str[0:3].str.replace(\"int\",\"NA\") \n",
    "    snvs_df['mut_aa'] = snvs_df['aa_change'].str[-3:].str.replace(\"ion\",\"NA\")\n",
    "    \n",
    "    # add in columns for nucleotide changes \n",
    "    snvs_df['nt_ref'] = snvs_df['nt_change'].str.split(\">\",expand=True)[0].str[-1:]\n",
    "    snvs_df['nt_mut'] = snvs_df['nt_change'].str.split(\">\",expand=True)[1]\n",
    "    # add in a column for the nucleotide mutation so that it is in the same format as the annotation on nextstrain\n",
    "    snvs_df['nuc_muts'] = snvs_df['nt_ref'] + snvs_df[\"POS_x\"].astype(int).astype(str) + snvs_df['nt_mut']\n",
    "\n",
    "    return(snvs_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_variant_as_indel_or_snv(nt_change):\n",
    "    if \"dup\" in nt_change or \"del\" in nt_change:\n",
    "        variant = \"indel\"\n",
    "    else:\n",
    "        variant = \"snv\"\n",
    "    return(variant)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_variant_type_column(within_host_df):\n",
    "    within_host_df['type_of_variant'] = within_host_df['nt_change'].apply(classify_variant_as_indel_or_snv)\n",
    "    \n",
    "    return(within_host_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_annotation_for_intergenic_regions(within_host_df):\n",
    "    #within_host_df['annotation'] = within_host_df['annotation'].replace('','intergenic_region')\n",
    "    within_host_df.annotation.fillna(value='intergenic_region', inplace=True)\n",
    "    return(within_host_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_number_to_strain(sampleid, strain_names_dict):\n",
    "    if sampleid in strain_names_dict:\n",
    "        strain_name = strain_names_dict[sampleid]\n",
    "    else:\n",
    "        strain_name = \"unknown\"\n",
    "        #print(sampleid, \" does not have a strain name\")\n",
    "    return(strain_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_in_strain_column(df, strain_names_dict):\n",
    "    temp_df = pd.DataFrame(df)\n",
    "    strain_name = temp_df['sampleid'].apply(convert_number_to_strain, args=[strain_names_dict])\n",
    "    #strain_name = temp_df['sampleid'].apply(lambda x: \"USA/\" + tube_number_conversion[x] + \"/2020\")\n",
    "    temp_df[\"strain_name\"] = strain_name\n",
    "    return(temp_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The following functions will look for consensus level variants and add in a column that correctly annotates the minor variant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_high_freq_variants_to_minor_variants_snvs(row):\n",
    "    frequency = row.frequency\n",
    "    variant_nt = row.nt_mut\n",
    "    variant_aa = row.mut_aa\n",
    "    ref_nt = row.nt_ref\n",
    "    ref_aa = row.wt_aa\n",
    "    \n",
    "    if frequency >= 0.5: \n",
    "        minor_frequency = 1 - frequency\n",
    "        consensus_base = variant_nt\n",
    "        consensus_aa = variant_aa\n",
    "        minor_base = ref_nt\n",
    "        minor_aa = ref_aa\n",
    "    else:\n",
    "        minor_frequency = frequency\n",
    "        consensus_base = ref_nt\n",
    "        consensus_aa = ref_aa\n",
    "        minor_base = variant_nt\n",
    "        minor_aa = variant_aa\n",
    "    \n",
    "    return(minor_frequency,consensus_base,minor_base,consensus_aa,minor_aa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_minor_variant_column_snvs(df):\n",
    "    temp_df = pd.DataFrame(df)\n",
    "    a = temp_df[['gene','frequency','nt_ref','nt_mut','mut_aa','wt_aa']].apply(convert_high_freq_variants_to_minor_variants_snvs, axis=1)\n",
    "    temp_df[\"a\"] = a\n",
    "    temp_df['minor_frequency'] = temp_df['a'].apply(lambda x: x[0])\n",
    "    temp_df['consensus_base'] = temp_df['a'].apply(lambda x: x[1])\n",
    "    temp_df['minor_base'] = temp_df['a'].apply(lambda x: x[2])\n",
    "    temp_df['consensus_aa'] = temp_df['a'].apply(lambda x: x[3])\n",
    "    temp_df['minor_aa'] = temp_df['a'].apply(lambda x: x[4])\n",
    "\n",
    "    temp_df['minor_nuc_muts'] = temp_df['consensus_base'] + temp_df['POS_x'].astype(int).astype(str) + temp_df['minor_base']\n",
    "    temp_df['minor_aa_muts'] = temp_df['gene'] + \"_\"+temp_df['consensus_aa'] + temp_df['aa_site'] + temp_df['minor_aa']\n",
    "    \n",
    "    temp_df.drop(\"a\",axis=1,inplace=True)\n",
    "    \n",
    "    return(temp_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use metadata to add in other columns for location and other data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_clade(strain_name, metadata):\n",
    "    if strain_name in metadata: \n",
    "        clade = metadata[strain_name]['clade']\n",
    "    else:\n",
    "        clade = \"unknown\"\n",
    "    return(clade)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_location(strain_name, metadata):\n",
    "    if strain_name in metadata: \n",
    "        location = metadata[strain_name]['location']\n",
    "    else:\n",
    "        location = \"unknown\"\n",
    "    return(location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_metadata_columns(df, metadata):\n",
    "    temp_df = pd.DataFrame(df)\n",
    "    location = temp_df['strain_name'].apply(add_location, args=[metadata])\n",
    "    clade = temp_df['strain_name'].apply(add_clade, args=[metadata])\n",
    "    #strain_name = temp_df['sampleid'].apply(lambda x: \"USA/\" + tube_number_conversion[x] + \"/2020\")\n",
    "    temp_df[\"location\"] = location\n",
    "    temp_df[\"clade\"] = clade\n",
    "    return(temp_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in homopolymer annotation module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run homopolymer-module.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run all of the above together to output all of the necessary dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_dataframes(metadata_file, clades_file, vcf_directory, to_ignore, fasta_file_path, homopolymer_length):\n",
    "    strain_names_dict = read_strain_names_from_csv(metadata_file)\n",
    "    metadata_dict = return_metadata_dict(metadata_file, clades_file)\n",
    "    vcfs = return_list_of_vcfs(vcf_directory)\n",
    "    \n",
    "    # read in intersection snvs, format the columns, and return intersection snvs dataframe\n",
    "    all_intersection_variants, samples_without_variants = read_in_intersection_snvs(vcfs, vcf_directory)\n",
    "    all_intersection_variants = format_snp_column(all_intersection_variants)\n",
    "    all_intersection_variants = add_in_strain_column(all_intersection_variants, strain_names_dict)\n",
    "    all_intersection_variants = all_intersection_variants[~all_intersection_variants['sampleid'].isin(to_ignore)]\n",
    "    all_intersection_variants = fix_annotation_for_intergenic_regions(all_intersection_variants)\n",
    "    \n",
    "    # add in location and clade data\n",
    "    all_intersection_variants = add_metadata_columns(all_intersection_variants, metadata_dict)\n",
    "    \n",
    "    # add in homopolymer annotation\n",
    "    all_intersection_variants = add_homopolymer_annotation(fasta_file_path, all_intersection_variants, homopolymer_length)\n",
    "    \n",
    "    # separate out snvs and indels\n",
    "    all_intersection_variants = add_variant_type_column(all_intersection_variants)\n",
    "    snvs_only = separate_snvs(all_intersection_variants)\n",
    "    \n",
    "    # add in a column for the minor variants \n",
    "    snvs_only = add_minor_variant_column_snvs(snvs_only)\n",
    "    \n",
    "    # print out samples that don't have variants\n",
    "    for s in samples_without_variants:\n",
    "        if s not in to_ignore:\n",
    "            print(\"tube\", s, \"strain\", strain_names_dict[s], \"does not have any variants\")\n",
    "    \n",
    "    return(snvs_only,all_intersection_variants, metadata_dict, strain_names_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LHM-basics (python3)",
   "language": "python",
   "name": "lhm-basics"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
