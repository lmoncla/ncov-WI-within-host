{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read in SNV vcfs and output dataframe \n",
    "\n",
    "August 14, 2020\n",
    "\n",
    "I am finding myself needing to read in these intersection vcf files and convert them to a dataframe and copying and pasting all of this code over and over again. Instead, I am going to try making this notebook, where I can do all the coding to return the dataframe I want, and then I can just import this into all the other analysis notebooks where I use this dataframe. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import pandas as pd \n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read in metadata "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_in_clades_file(clades_file):\n",
    "    clades_dict = {}\n",
    "    with open(clades_file, \"r\") as infile:\n",
    "        for line in infile:\n",
    "            strain_name = line.split(\"\\t\")[0]\n",
    "            clade = line.split(\"\\t\")[1].strip()\n",
    "        \n",
    "            clades_dict[strain_name] = clade\n",
    "    return(clades_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_strain_name(samplename):\n",
    "    strain_name = samplename.replace(\"hCoV-19/\",\"\")\n",
    "\n",
    "    if \"USA\" not in strain_name: \n",
    "        strain_name = \"USA/\" + strain_name\n",
    "    if \"/2020\" not in strain_name:\n",
    "        strain_name = strain_name + \"/2020\"\n",
    "        \n",
    "    return(strain_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_metadata_dict(metadata_file, clades_file):\n",
    "    x = {}\n",
    "    clades_dict = read_in_clades_file(clades_file)\n",
    "    \n",
    "    with open(metadata_file, \"r\") as infile: \n",
    "        for line in infile:\n",
    "            if \"Barcode\" not in line:   # skip first line\n",
    "                samplename = line.split(\"\\t\")[0]\n",
    "                strain_name = fix_strain_name(samplename)\n",
    "                geo = line.split(\"\\t\")[8].title()\n",
    "                Ct1 = line.split(\"\\t\")[22]\n",
    "                Ct2 = line.split(\"\\t\")[23]\n",
    "                household = line.split(\"\\t\")[33]\n",
    "                \n",
    "                # read in clade\n",
    "                if strain_name in clades_dict:\n",
    "                    clade = clades_dict[strain_name]\n",
    "                else:\n",
    "                    clade = \"unknown\"\n",
    "                \n",
    "                if geo == \"Oregon\":\n",
    "                    geo = \"Oregon WI\"\n",
    "                if geo == \"Columbus\":\n",
    "                    geo = \"Columbus WI\"\n",
    "                if geo == \"Verona\":\n",
    "                    geo = \"Verona WI\"\n",
    "                if \"Dane\" in geo: \n",
    "                    geo = \"Dane County\"\n",
    "\n",
    "                x[strain_name] = {\"location\":geo, \"Ct1\":Ct1, \"Ct2\": Ct2, \"household\":household, \"clade\":clade}\n",
    "    \n",
    "    return(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The following functions are all for reading in csv iles and formatting into pandas dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_list_of_vcfs(vcf_directory):\n",
    "    vcf_list = []\n",
    "    for f in glob.glob(vcf_directory + \"*intersection.csv\"):\n",
    "        vcf_list.append(f)\n",
    "    return(vcf_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_in_intersection_snvs(vcf_list, vcf_directory):\n",
    "    within_host_df = pd.DataFrame()\n",
    "    \n",
    "    for v in vcf_list:\n",
    "        # pull out sampleid\n",
    "        sampleid = v.replace(vcf_directory,\"\").replace(\"-intersection.csv\",\"\")\n",
    "        \n",
    "        d = pd.read_csv(v, sep=\"\\t\")\n",
    "        d['sampleid'] = sampleid\n",
    "        within_host_df = within_host_df.append(d)\n",
    "        \n",
    "    return(within_host_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_strain_names_from_csv(strain_names_file):\n",
    "    strain_names_dict = {}\n",
    "    \n",
    "    with open(strain_names_file, \"r\") as infile: \n",
    "        for line in infile:\n",
    "            if \"Sample identifier\" not in line:\n",
    "                tube_number = line.split(\"\\t\")[1]\n",
    "                samplename = line.split(\"\\t\")[0]\n",
    "                strain_name = fix_strain_name(samplename)\n",
    "                hospital_id = line.split(\"\\t\")[2]\n",
    "                \n",
    "                # there are 2 sets of tube numbers, some with leading 0s and others without. I am pretty sure we\n",
    "                # want the ones with leading 0s; there are also some we don't want that have non-numeric tube #s\n",
    "                if tube_number.isdigit() and tube_number.startswith(\"0\"):\n",
    "                    strain_names_dict[str(int(tube_number))] = strain_name\n",
    "               \n",
    "                else:\n",
    "                    # I need to clean up the promega tube numbers as well\n",
    "                    if \"Promega\" in hospital_id: \n",
    "                        new_tube_number = tube_number.replace(\" (from State Lab via Promega)\",\"\").replace(\"nCov-\",\"\") + \"P\"\n",
    "                        strain_names_dict[new_tube_number] = strain_name\n",
    "                    else:\n",
    "                        strain_names_dict[tube_number] = strain_name\n",
    "                            \n",
    "    \n",
    "    return(strain_names_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_snp_column(df):\n",
    "    \n",
    "    # separate the SNP column into gene\n",
    "    df['annotation'] = df['SNP'].str.split(\"_\", expand=True)[3]\n",
    "    df['gene'] = df['SNP'].str.split(\"_\", expand=True)[0]\n",
    "    df['nt_change'] = df['SNP'].str.split(\"_\", expand=True)[1]\n",
    "    df['aa_change'] = df['SNP'].str.split(\"_\", expand=True)[2]\n",
    "    \n",
    "    # change % to string\n",
    "    df = df.rename(columns = {'%':'frequency'})\n",
    "    \n",
    "    return(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def separate_snvs(within_host_df):\n",
    "    # first, separate out and format snvs_df\n",
    "    snvs_df = within_host_df[(within_host_df['annotation'] == \"missense\") | (within_host_df['annotation'] == \"synonymous\") | (within_host_df['annotation'] == \"stop\")]\n",
    "    snvs_df['aa_site'] = snvs_df['aa_change'].str[3:-3]\n",
    "    snvs_df['wt_aa'] = snvs_df['aa_change'].str[0:3]\n",
    "    snvs_df['mut_aa'] = snvs_df['aa_change'].str[-3:]\n",
    "    \n",
    "    # add in columns for nucleotide changes \n",
    "    snvs_df['nt_ref'] = snvs_df['nt_change'].str.split(\">\",expand=True)[0].str[-1:]\n",
    "    snvs_df['nt_mut'] = snvs_df['nt_change'].str.split(\">\",expand=True)[1]\n",
    "    # add in a column for the nucleotide mutation so that it is in the same format as the annotation on nextstrain\n",
    "    snvs_df['nuc_muts'] = snvs_df['nt_ref'] + snvs_df[\"POS_x\"].astype(int).astype(str) + snvs_df['nt_mut']\n",
    "\n",
    "    return(snvs_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_indels(row):\n",
    "    \n",
    "    if \"dup\" in row['nt_change']:\n",
    "        split_char = \"dup\"\n",
    "        variant = row['nt_change'].split(split_char)[1]\n",
    "        new_value = \"-\" + str(int(row[\"POS_x\"])) + variant\n",
    "        nt_ref = \"-\"\n",
    "        nt_mut = variant\n",
    "    \n",
    "    elif \"del\" in row['nt_change']:\n",
    "        split_char = \"del\"\n",
    "        variant = row['nt_change'].split(split_char)[1]\n",
    "        new_value = str(int(row['POS_x'])) +  variant + \"-\"\n",
    "        nt_ref = variant\n",
    "        nt_mut = \"-\"\n",
    "    \n",
    "    return(new_value, nt_ref, nt_mut)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_indel_type(row):\n",
    "    \n",
    "    if \"dup\" in row['nt_change']:\n",
    "        type_change = \"insertion\"\n",
    "     \n",
    "    elif \"del\" in row['nt_change']:\n",
    "        type_change = \"deletion\"\n",
    "    \n",
    "    return(type_change)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def separate_indels(within_host_df):\n",
    "        \n",
    "    # now, separate out and format indels dataframe\n",
    "    indels_df = within_host_df[(within_host_df['annotation'] == \"frameshift\") | (within_host_df['annotation'] == \"frameshift&stop\")]\n",
    "    \n",
    "    # add a column with formatted indel that matches nextstrain\n",
    "    # add in nt_ref and nt_mut columns so that they match snvs dataframe\n",
    "    indels_df['a'] = indels_df.apply(format_indels, axis=1)\n",
    "    indels_df['nuc_muts'] =indels_df['a'].apply(lambda x: x[0])\n",
    "    indels_df['nt_ref'] =indels_df['a'].apply(lambda x: x[1])\n",
    "    indels_df['nt_mut'] =indels_df['a'].apply(lambda x: x[2])\n",
    "    indels_df.drop(\"a\",axis=1,inplace=True)\n",
    "    \n",
    "    indels_df['type_mut'] = indels_df.apply(return_indel_type, axis=1)\n",
    "    \n",
    "    return(indels_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_number_to_strain(sampleid, strain_names_dict):\n",
    "    if sampleid in strain_names_dict:\n",
    "        strain_name = strain_names_dict[sampleid]\n",
    "    else:\n",
    "        strain_name = \"unknown\"\n",
    "        #print(sampleid, \" does not have a strain name\")\n",
    "    return(strain_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_in_strain_column(df, strain_names_dict):\n",
    "    temp_df = pd.DataFrame(df)\n",
    "    strain_name = temp_df['sampleid'].apply(convert_number_to_strain, args=[strain_names_dict])\n",
    "    #strain_name = temp_df['sampleid'].apply(lambda x: \"USA/\" + tube_number_conversion[x] + \"/2020\")\n",
    "    temp_df[\"strain_name\"] = strain_name\n",
    "    return(temp_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The following functions will look for consensus level variants and add in a column that correctly annotates the minor variant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_high_freq_variants_to_minor_variants(row):\n",
    "    frequency = row.frequency\n",
    "    variant_nt = row.nt_mut\n",
    "    ref_nt = row.nt_ref\n",
    "    \n",
    "    if frequency >= 0.5: \n",
    "        minor_frequency = 1 - frequency\n",
    "        consensus_base = variant_nt\n",
    "        minor_base = ref_nt\n",
    "    else:\n",
    "        minor_frequency = frequency\n",
    "        consensus_base = ref_nt\n",
    "        minor_base = variant_nt\n",
    "    \n",
    "    return(minor_frequency,consensus_base,minor_base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_minor_variant_column(df):\n",
    "    temp_df = pd.DataFrame(df)\n",
    "    a = temp_df[['frequency','nt_ref','nt_mut']].apply(convert_high_freq_variants_to_minor_variants, axis=1)\n",
    "    temp_df[\"a\"] = a\n",
    "    temp_df['minor_frequency'] = temp_df['a'].apply(lambda x: x[0])\n",
    "    temp_df['consensus_base'] = temp_df['a'].apply(lambda x: x[1])\n",
    "    temp_df['minor_base'] = temp_df['a'].apply(lambda x: x[2])\n",
    "    temp_df['minor_nuc_muts'] = temp_df['consensus_base'] + temp_df['POS_x'].astype(int).astype(str) + temp_df['minor_base']\n",
    "    \n",
    "    temp_df.drop(\"a\",axis=1,inplace=True)\n",
    "    \n",
    "    return(temp_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use metadata to add in other columns for location and other data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_clade(strain_name, metadata):\n",
    "    if strain_name in metadata: \n",
    "        clade = metadata[strain_name]['clade']\n",
    "    else:\n",
    "        clade = \"unknown\"\n",
    "    return(clade)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_location(strain_name, metadata):\n",
    "    if strain_name in metadata: \n",
    "        location = metadata[strain_name]['location']\n",
    "    else:\n",
    "        location = \"unknown\"\n",
    "    return(location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_metadata_columns(df, metadata):\n",
    "    temp_df = pd.DataFrame(df)\n",
    "    location = temp_df['strain_name'].apply(add_location, args=[metadata])\n",
    "    clade = temp_df['strain_name'].apply(add_clade, args=[metadata])\n",
    "    #strain_name = temp_df['sampleid'].apply(lambda x: \"USA/\" + tube_number_conversion[x] + \"/2020\")\n",
    "    temp_df[\"location\"] = location\n",
    "    temp_df[\"clade\"] = clade\n",
    "    return(temp_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in homopolymer annotation module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run homopolymer-module.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run all of the above together to output all of the necessary dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_dataframes(metadata_file, clades_file, vcf_directory, to_ignore, fasta_file_path):\n",
    "    strain_names_dict = read_strain_names_from_csv(metadata_file)\n",
    "    metadata_dict = return_metadata_dict(metadata_file, clades_file)\n",
    "    vcfs = return_list_of_vcfs(vcf_directory)\n",
    "    \n",
    "    # read in intersection snvs, format the columns, and return intersection snvs dataframe\n",
    "    all_intersection_variants = read_in_intersection_snvs(vcfs, vcf_directory)\n",
    "    all_intersection_variants = format_snp_column(all_intersection_variants)\n",
    "    all_intersection_variants = add_in_strain_column(all_intersection_variants, strain_names_dict)\n",
    "    all_intersection_variants = all_intersection_variants[~all_intersection_variants['sampleid'].isin(to_ignore)]\n",
    "    \n",
    "    # add in location and clade data\n",
    "    all_intersection_variants = add_metadata_columns(all_intersection_variants, metadata_dict)\n",
    "    \n",
    "    # add in homopolymer annotation\n",
    "    all_intersection_variants = add_homopolymer_annotation(fasta_file_path, all_intersection_variants)\n",
    "    \n",
    "    # separate out snvs and indels \n",
    "    snvs_only = separate_snvs(all_intersection_variants)\n",
    "    indels_only = separate_indels(all_intersection_variants)\n",
    "    \n",
    "    # add in a column for the minor variants \n",
    "    snvs_only = add_minor_variant_column(snvs_only)\n",
    "    indels_only = add_minor_variant_column(indels_only)\n",
    "    \n",
    "    # remove very low frequency variants\n",
    "    snvs_only = snvs_only[snvs_only['minor_frequency'] >= 0.01]\n",
    "    indels_only = indels_only[indels_only['minor_frequency'] >= 0.01]\n",
    "\n",
    "    return(snvs_only, indels_only, all_intersection_variants, metadata_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LHM-basics (python3)",
   "language": "python",
   "name": "lhm-basics"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
